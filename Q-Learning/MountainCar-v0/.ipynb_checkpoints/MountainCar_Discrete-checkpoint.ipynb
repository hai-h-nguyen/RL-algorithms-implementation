{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "<class 'gym.spaces.box.Box'>\n",
      "<class 'gym.spaces.discrete.Discrete'>\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "\n",
    "# State: \n",
    "num_states = env.observation_space\n",
    "num_actions = env.action_space\n",
    "\n",
    "print(type(num_states))\n",
    "print(type(num_actions))\n",
    "\n",
    "# # Init Q-Table\n",
    "# Q_table = np.zeros([num_states, num_actions])\n",
    "\n",
    "# learning_rate = 0.1\n",
    "# discount_factor = 0.9\n",
    "# epsilon = 1.0\n",
    "# max_epsilon = 1.0\n",
    "# min_epsilon = 0.01\n",
    "\n",
    "# n_episodes = 50000\n",
    "\n",
    "# for episode in range(1, n_episodes + 1):\n",
    "#     state = env.reset()  \n",
    "#     done = False\n",
    "    \n",
    "#     while (not done):    \n",
    "#         # Either explore or exploit (will exploit more increasingly)\n",
    "#         random_val = np.random.rand()\n",
    "#         if (random_val < epsilon):    \n",
    "#             action = env.action_space.sample()\n",
    "#         else:\n",
    "#             action = np.argmax(Q_table[state, :])\n",
    "            \n",
    "#         # Perform the action\n",
    "#         next_state, reward, done, info = env.step(action)        \n",
    "              \n",
    "#         # Maximum expected future reward one steps from the next state\n",
    "#         next_max = np.max(Q_table[next_state, :])\n",
    "          \n",
    "#         # Update Q-Table\n",
    "#         Q_table[state, action] = Q_table[state, action] + learning_rate * (reward + discount_factor * next_max - Q_table[state, action])\n",
    "        \n",
    "#         # Assign new state\n",
    "#         state = next_state\n",
    "        \n",
    "#     # Reduce exploration\n",
    "#     epsilon = min_epsilon + (max_epsilon - min_epsilon) * (1 - episode/n_episodes)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run with random agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score: -200.0\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "score = 0\n",
    "for t in range(200):\n",
    "    action = env.action_space.sample()\n",
    "    env.render()\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    score += reward\n",
    "    if done:\n",
    "        break \n",
    "print('Final score:', score)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State space: Box(2,)\n",
      "- low: [-1.2  -0.07]\n",
      "- high: [0.6  0.07]\n"
     ]
    }
   ],
   "source": [
    "# Explore state (observation) space\n",
    "print(\"State space:\", env.observation_space)\n",
    "print(\"- low:\", env.observation_space.low)\n",
    "print(\"- high:\", env.observation_space.high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: Discrete(3)\n",
      "Action space samples:\n",
      "[0 2 2 0 2 2 2 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Explore the action space\n",
    "print(\"Action space:\", env.action_space)\n",
    "\n",
    "# Generate some samples from the action space\n",
    "print(\"Action space samples:\")\n",
    "print(np.array([env.action_space.sample() for i in range(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_uniform_grid(low, high, bins=(10, 10)):\n",
    "    \"\"\"Define a uniformly-spaced grid that can be used to discretize a space.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    low : array_like\n",
    "        Lower bounds for each dimension of the continuous space.\n",
    "    high : array_like\n",
    "        Upper bounds for each dimension of the continuous space.\n",
    "    bins : tuple\n",
    "        Number of bins along each corresponding dimension.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    grid : list of array_like\n",
    "        A list of arrays containing split points for each dimension.\n",
    "    \"\"\"\n",
    "    step = (high[0] - low[0]) / bins[0]\n",
    "    array_a = low[0] + np.arange(1, bins[0]) * step\n",
    "    \n",
    "    step = (high[1] - low[1]) / bins[1]\n",
    "    array_b = low[1] + np.arange(1, bins[1]) * step    \n",
    "    # TODO: Implement this\n",
    "    return [array_a, array_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low = [-1.0, -5.0]\n",
    "high = [1.0, 5.0]\n",
    "create_uniform_grid(low, high)  # [test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples:\n",
      "array([[-1.  , -5.  ],\n",
      "       [-0.81, -4.1 ],\n",
      "       [-0.8 , -4.  ],\n",
      "       [-0.5 ,  0.  ],\n",
      "       [ 0.2 , -1.9 ],\n",
      "       [ 0.8 ,  4.  ],\n",
      "       [ 0.81,  4.1 ],\n",
      "       [ 1.  ,  5.  ]])\n",
      "\n",
      "Discretized samples:\n",
      "array([[[0., 0.]],\n",
      "\n",
      "       [[0., 0.]],\n",
      "\n",
      "       [[1., 1.]],\n",
      "\n",
      "       [[2., 5.]],\n",
      "\n",
      "       [[5., 3.]],\n",
      "\n",
      "       [[9., 9.]],\n",
      "\n",
      "       [[9., 9.]],\n",
      "\n",
      "       [[9., 9.]]])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "def discretize_(sample, grid):\n",
    "    \"\"\"Discretize a sample as per given grid.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sample : array_like\n",
    "        A single sample from the (original) continuous space.\n",
    "    grid : list of array_like\n",
    "        A list of arrays containing split points for each dimension.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    discretized_sample : array_like\n",
    "        A sequence of integers with the same number of dimensions as sample.\n",
    "    \"\"\"\n",
    "    world_size = samples[0].shape[0]\n",
    "    \n",
    "    sample_index = 0\n",
    "    \n",
    "    results = np.zeros([1,2])\n",
    "      \n",
    "    # Loop all dimensions\n",
    "    for index in range(world_size):\n",
    "        # Find the index of samples for each dimension\n",
    "        inds = np.digitize(sample[index], grid[index])\n",
    "        results[0][index] = inds\n",
    "        \n",
    "    return results\n",
    "\n",
    "\n",
    "# Test with a simple grid and some samples\n",
    "grid = create_uniform_grid([-1.0, -5.0], [1.0, 5.0])\n",
    "samples = np.array(\n",
    "    [[-1.0 , -5.0],\n",
    "     [-0.81, -4.1],\n",
    "     [-0.8 , -4.0],\n",
    "     [-0.5 ,  0.0],\n",
    "     [ 0.2 , -1.9],\n",
    "     [ 0.8 ,  4.0],\n",
    "     [ 0.81,  4.1],\n",
    "     [ 1.0 ,  5.0]])\n",
    "discretized_samples = np.array([discretize_(sample, grid) for sample in samples])\n",
    "print(\"\\nSamples:\", repr(samples), sep=\"\\n\")\n",
    "print(\"\\nDiscretized samples:\", repr(discretized_samples), sep=\"\\n\")\n",
    "\n",
    "print(samples[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discretized_samples.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
