{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Recurrent Q-Networks in Pytorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import os\n",
    "from collections import namedtuple\n",
    "import gym\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import more_itertools as mitt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "from collections import deque\n",
    "import random\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from baselines import logger\n",
    "import pickle\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = [12, 4]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_global_seeds(seed):\n",
    "    \"\"\"Set random seeds for numpy, random, and pytorch\n",
    "\n",
    "    Args:\n",
    "        seed: random seed to be set\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"    \n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_average(data, *, window_size):\n",
    "    \"\"\"Smoothen the 1-d data array using a rollin average.\n",
    "\n",
    "    Args:\n",
    "        data: 1-d numpy.array\n",
    "        window_size: size of the smoothing window\n",
    "\n",
    "    Returns:\n",
    "        smooth_data: a 1-d numpy.array with the same size as data\n",
    "    \"\"\"\n",
    "    assert data.ndim == 1\n",
    "    kernel = np.ones(window_size)\n",
    "    smooth_data = np.convolve(data, kernel) / np.convolve(\n",
    "        np.ones_like(data), kernel\n",
    "    )\n",
    "    return smooth_data[: -window_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action_epsilon_greedy(dqn_model, obs, hidden_state, cell_state, eps, device, env):\n",
    "    \"\"\"Select action using epsilon greedy.\n",
    "\n",
    "    Args:\n",
    "        dqn_model: The current estimate of Q-value\n",
    "        obs: observation\n",
    "        hidden_state: hidden state\n",
    "        cell_state: cell state\n",
    "        eps: current value of epsilon\n",
    "        device: cuda or cpu\n",
    "        env: current environment used\n",
    "\n",
    "    Returns:\n",
    "        action, next hidden_state, next cell_state\n",
    "    \"\"\"    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if np.random.rand() < eps:\n",
    "                torch_x = torch.FloatTensor(obs).to(device)\n",
    "                model_out = dqn_model.forward(torch_x, 1, 1, hidden_state, cell_state)\n",
    "                action = np.random.randint(0, env.action_space.n)\n",
    "        else:\n",
    "                torch_x = torch.FloatTensor(obs).to(device)\n",
    "                model_out = dqn_model.forward(torch_x, 1, 1, hidden_state, cell_state)\n",
    "                out = model_out[0]\n",
    "                action = int(torch.argmax(out[0]))\n",
    "\n",
    "        hidden_state = model_out[1][0]\n",
    "        cell_state = model_out[1][1]\n",
    "    return action, hidden_state, cell_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LinearSchedule:\n",
    "    def __init__(self, value_from, value_to, nsteps):\n",
    "        \"\"\"Linear schedule from `value_from` to `value_to` in `nsteps` steps.\n",
    "\n",
    "        :param value_from: initial value\n",
    "        :param value_to: final value\n",
    "        :param nsteps: number of steps for the linear schedule\n",
    "        \"\"\"\n",
    "        self.value_from = value_from\n",
    "        self.value_to = value_to\n",
    "        self.nsteps = nsteps\n",
    "\n",
    "    def value(self, step) -> float:\n",
    "        \"\"\"Return interpolated value between `value_from` and `value_to`.\n",
    "\n",
    "        returns {\n",
    "            `value_from`, if step == 0 or less\n",
    "            `value_to`, if step == nsteps - 1 or more\n",
    "            the interpolation between `value_from` and `value_to`, if 0 <= steps < nsteps\n",
    "        }\n",
    "\n",
    "        :param step:  The step at which to compute the interpolation.\n",
    "        :rtype: float.  The interpolated value.\n",
    "        \"\"\"\n",
    "\n",
    "        if (step < 0):\n",
    "            return self.value_from\n",
    "        \n",
    "        if (step >= self.nsteps - 1):\n",
    "            return self.value_to\n",
    "        \n",
    "        step_size = (self.value_to - self.value_from) / (self.nsteps - 1);\n",
    "        value = self.value_from + step * step_size; \n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentReplayMemory:\n",
    "    def __init__(self, max_size, episode_min_len, episode_max_len):\n",
    "        \"\"\"Replay memory implemented as a queue.\n",
    "\n",
    "        Args:\n",
    "            - max_size: Maximum size of the buffer.\n",
    "            - episode_min_len: minimum length of an eligible episode\n",
    "            - episode_max_len: maximimum length of an eligible episode\n",
    "        \"\"\"\n",
    "        self.max_size = max_size\n",
    "        self.memory = deque(maxlen = self.max_size)\n",
    "        self.episode_min_len = episode_min_len\n",
    "        self.episode_max_len = episode_max_len\n",
    "\n",
    "    def add_episode(self, episode):\n",
    "        \"\"\"Add an episode to the buffer.\n",
    "\n",
    "        :param episode:  episode to add.\n",
    "        \"\"\"\n",
    "        assert len(episode) >= self.episode_min_len\n",
    "        self.memory.append(episode)\n",
    "\n",
    "    def pre_populate(self, env, replay_prepopulate_episodes):\n",
    "        \"\"\"Prepopulate the replay buffer before training.\n",
    "\n",
    "        Args:\n",
    "            - env: Environment to run\n",
    "            - replay_prepopulate_episodes: How many episodes to pre-populate\n",
    "        \"\"\"\n",
    "\n",
    "        episode_cnt = 0\n",
    "        while episode_cnt < replay_prepopulate_episodes:\n",
    "            \n",
    "            state = env.reset()\n",
    "            state = state[[0, 2]]\n",
    "\n",
    "            step_count = 0\n",
    "            episode = []\n",
    "            \n",
    "            while step_count < self.episode_max_len:\n",
    "                \n",
    "                step_count += 1\n",
    "                action = np.random.randint(0, env.action_space.n)\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "                next_state = next_state[[0, 2]]\n",
    "\n",
    "                episode.append((state, action, reward, next_state, done))\n",
    "                \n",
    "                state = next_state\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "            \n",
    "            if (len(episode) > self.episode_min_len):\n",
    "                self.add_episode(episode)\n",
    "                episode_cnt += 1\n",
    "                \n",
    "        print('Done pre-populated with %d episodes'%(len(self.memory)))         \n",
    "        \n",
    "\n",
    "    def sample(self, batch_size, episode_len):\n",
    "        \"\"\"Sample a batch of episodes.\n",
    "\n",
    "        :param batch_size:  Number of episodes to sample.\n",
    "        :param episode_len:  Minimum length of the episode.\n",
    "        :rtype: Batch (list)\n",
    "        \"\"\"\n",
    "\n",
    "        sampled_episodes = random.sample(self.memory, batch_size)\n",
    "        batch = []\n",
    "        for episode in sampled_episodes:\n",
    "            if len(episode) + 1 - episode_len > 0:\n",
    "                point = np.random.randint(0, len(episode) + 1 - episode_len)\n",
    "                batch.append(episode[point : point + episode_len])\n",
    "\n",
    "        assert len(batch) == batch_size\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRQN(nn.Module):\n",
    "    def __init__(self, obs_dim=2, action_dim=4, fc_hidden_dim=256, rnn_hidden_dim=512):\n",
    "        \"\"\"Deep Recurrent Q-Network PyTorch model.\n",
    "\n",
    "        Args:\n",
    "            - obs_dim: Dimensionality of observations\n",
    "            - action_dim: Dimensionality of actions\n",
    "            - hidden_dim: Dimesionality of the rnn hidden layer\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.obs_dim = obs_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.fc_hidden_dim = fc_hidden_dim\n",
    "        self.rnn_hidden_dim = rnn_hidden_dim\n",
    "\n",
    "        self.fc1 = nn.Linear(self.obs_dim, self.fc_hidden_dim)\n",
    "        self.fc2 = nn.Linear(self.fc_hidden_dim, self.fc_hidden_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size = self.fc_hidden_dim, hidden_size = self.rnn_hidden_dim, num_layers = 1, batch_first = True)\n",
    "        self.fc4 = nn.Linear(self.rnn_hidden_dim, self.action_dim)\n",
    "\n",
    "    def forward(self, observations, bsize, episode_length, hidden_state, cell_state) -> torch.Tensor:\n",
    "        \"\"\"Q function mapping from states to action-values.\n",
    "\n",
    "        :param obs: (*, S) torch.Tensor where * is any number of additional\n",
    "                dimensions, and S is the dimensionality of observation-space.\n",
    "        :rtype: (*, A) torch.Tensor where * is the same number of additional\n",
    "                dimensions as the `states`, and A is the dimensionality of the\n",
    "                action-space.  This represents the Q values Q(s, .).\n",
    "        \"\"\"\n",
    "        observations = observations.view(bsize * episode_length, 1, self.obs_dim)\n",
    "        x = F.relu(self.fc1(observations))\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        x = x.view(bsize, episode_length, self.fc_hidden_dim)\n",
    "        lstm_out = self.lstm(x, (hidden_state, cell_state))\n",
    "#         out = lstm_out[0][:, episode_length-1, :]\n",
    "        out = lstm_out[0]\n",
    "        h_n = lstm_out[1][0]\n",
    "        c_n = lstm_out[1][1]\n",
    "\n",
    "        x = self.fc4(out)\n",
    "\n",
    "        return x, (h_n, c_n)     \n",
    "        \n",
    "    def init_hidden_states(self, bsize):\n",
    "        \"\"\"Init hidden state values.\n",
    "\n",
    "        :param bsize: batch_size\n",
    "        :rtype: zeros tensors\n",
    "        \"\"\"\n",
    "\n",
    "        h = torch.zeros(1, bsize, self.rnn_hidden_dim).float().to(device)\n",
    "        c = torch.zeros(1, bsize, self.rnn_hidden_dim).float().to(device)\n",
    "        \n",
    "        return h,c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single batch-update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_drqn_batch(optimizer, batch, episode_training_len, dqn_model, dqn_target, gamma):\n",
    "    \"\"\"Perform a single batch-update step on the given DQN model.\n",
    "    :param optimizer: nn.optim.Optimizer instance.\n",
    "    :param batch:  Batch of episodes.\n",
    "    :param episode_training_len: The length of the episode to be trained (fixed).\n",
    "    :param dqn_model:  The DQN model to be trained.\n",
    "    :param dqn_target:  The target DQN model, ~NOT~ to be trained.\n",
    "    :param gamma:  The discount factor.\n",
    "    :rtype: float  The scalar loss associated with this batch.\n",
    "    \"\"\"    \n",
    "    current_states = []\n",
    "    acts = []\n",
    "    rewards = []\n",
    "    next_states = []\n",
    "    dones = []\n",
    "\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    hidden_batch, cell_batch = dqn_model.init_hidden_states(batch_size)\n",
    "\n",
    "    for b in batch:\n",
    "        cs, ac, rw, ns, ds = [],[],[],[],[]\n",
    "        for element in b:\n",
    "            cs.append(element[0])\n",
    "            ac.append(element[1])\n",
    "            rw.append(element[2])\n",
    "            ns.append(element[3])\n",
    "            ds.append(element[4])\n",
    "        current_states.append(cs)\n",
    "        acts.append(ac)\n",
    "        rewards.append(rw)\n",
    "        next_states.append(ns)\n",
    "        dones.append(ds)\n",
    "    \n",
    "    torch_current_states = torch.FloatTensor(current_states).to(device)\n",
    "    torch_acts = torch.LongTensor(acts).to(device)\n",
    "    torch_rewards = torch.FloatTensor(rewards).to(device)\n",
    "    torch_next_states = torch.FloatTensor(next_states).to(device)\n",
    "    dones = torch.FloatTensor(dones).to(device)\n",
    "    \n",
    "    Q_next, _ = dqn_target.forward(torch_next_states, batch_size, episode_training_len, hidden_batch, cell_batch)\n",
    "    Q_next_max, _ = Q_next.detach().max(dim = 2)\n",
    "#     target_values = torch_rewards[:, episode_training_len - 1] + (gamma * Q_next_max) * (1 - dones[:, -1])\n",
    "    target_values = torch_rewards + (gamma * Q_next_max) * (1 - dones)\n",
    "    \n",
    "    Q_s, _ = dqn_model.forward(torch_current_states, batch_size, episode_training_len, hidden_batch, cell_batch)\n",
    "#     Q_s_a = Q_s.gather(dim=1,index=torch_acts[:, episode_training_len - 1].unsqueeze(dim = 1)).squeeze(dim = 1)\n",
    "    Q_s_a = Q_s.gather(dim=2,index=torch_acts.unsqueeze(dim = 2)).squeeze(dim = 2)\n",
    "\n",
    "    # testing that they share the same shapes\n",
    "    assert (\n",
    "        Q_s_a.shape == target_values.shape\n",
    "    ), 'Shapes of values tensor and target_values tensor do not match.'    \n",
    "    \n",
    "    # testing that the value tensor requires a gradient,\n",
    "    # and the target_values tensor does not\n",
    "    assert Q_s_a.requires_grad, 'values tensor should require gradients'\n",
    "    assert (\n",
    "        not target_values.requires_grad\n",
    "    ), 'target_values tensor should require gradients'\n",
    "\n",
    "    loss = F.mse_loss(Q_s_a, target_values)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dqn(\n",
    "    env,\n",
    "    num_timesteps,\n",
    "    *,\n",
    "    replay_size,\n",
    "    batch_size,\n",
    "    exploration,\n",
    "    gamma, \n",
    "    train_freq=1,\n",
    "    print_freq=100,\n",
    "    model_save_freq=500,\n",
    "    target_network_update_freq=500,\n",
    "    num_prepopulate_episode=100, \n",
    "    episode_training_len=8, \n",
    "    episode_max_len=30):\n",
    "    \"\"\"\n",
    "    DQN algorithm.\n",
    "\n",
    "    Compared to previous training procedures, we will train for a given number\n",
    "    of time-steps rather than a given number of episodes.  The number of\n",
    "    time-steps will be in the range of millions, which still results in many\n",
    "    episodes being executed.\n",
    "\n",
    "    Args:\n",
    "        - env: The openai Gym environment\n",
    "        - num_episodes: Total number of steps to be used for training\n",
    "        - replay_size: Maximum size of the ReplayMemory\n",
    "        - batch_size: Number of experiences in a batch\n",
    "        - exploration: a ExponentialSchedule\n",
    "        - gamma: The discount factor\n",
    "        - train_freq:\n",
    "        - print_freq:\n",
    "        - target_network_update_freq:\n",
    "        - num_prepopulate_episode:\n",
    "        - t_time_steps\n",
    "        - t_max_steps\n",
    "\n",
    "    Returns: (saved_models, returns)\n",
    "        - saved_models: Dictionary whose values are trained DQN models\n",
    "        - returns: Numpy array containing the return of each training episode\n",
    "        - lengths: Numpy array containing the length of each training episode\n",
    "        - losses: Numpy array containing the loss of each training batch\n",
    "    \"\"\"\n",
    "    # check that environment states are compatible with our DQN representation\n",
    "    assert (\n",
    "        isinstance(env.observation_space, gym.spaces.Box)\n",
    "        and len(env.observation_space.shape) == 1\n",
    "    )\n",
    "\n",
    "    # initialize the DQN and DQN-target models\n",
    "    dqn_model = DRQN().float().to(device)\n",
    "    dqn_target = DRQN().float().to(device)\n",
    "\n",
    "    dqn_target.load_state_dict(dqn_model.state_dict())\n",
    "\n",
    "    # initialize the optimizer\n",
    "    optimizer = torch.optim.Adam(dqn_model.parameters(), lr=5e-4)\n",
    "\n",
    "    # initialize the replay memory and prepopulating with some episodes\n",
    "    replay_buffer = RecurrentReplayMemory(replay_size, episode_training_len, episode_max_len)\n",
    "    replay_buffer.pre_populate(env, num_prepopulate_episode)\n",
    "\n",
    "    last_100ep_returns = deque(maxlen=100)\n",
    "    last_100ep_lens = deque(maxlen=100)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    t_total_steps = 0\n",
    "    t_episode = 0\n",
    "    short_episode_cnt = 0\n",
    "    good_episode_cnt = 0\n",
    "\n",
    "    # start training for a number of time steps\n",
    "    while t_total_steps < num_timesteps:\n",
    "\n",
    "        prev_state = env.reset()\n",
    "        # Extract the angle and cart position\n",
    "        prev_state = prev_state[[0, 2]]\n",
    "\n",
    "        currrent_episode = []\n",
    "\n",
    "        episode_return = 0\n",
    "        rewards = []\n",
    "        episode_len_count = 0\n",
    "\n",
    "        hidden_state, cell_state = dqn_model.init_hidden_states(bsize=1)\n",
    "\n",
    "        while episode_len_count < episode_max_len:\n",
    "            \n",
    "            episode_len_count += 1\n",
    "            t_total_steps += 1\n",
    "            \n",
    "            epsilon = exploration.value(t_total_steps)\n",
    "\n",
    "            if np.random.rand() < epsilon:\n",
    "                torch_x = torch.from_numpy(prev_state).float().to(device)\n",
    "                model_out = dqn_model.forward(torch_x, 1, 1, hidden_state, cell_state)\n",
    "                action = np.random.randint(0, env.action_space.n)\n",
    "                hidden_state = model_out[1][0]\n",
    "                cell_state = model_out[1][1]\n",
    "                \n",
    "            else:\n",
    "                torch_x = torch.from_numpy(prev_state).float().to(device)\n",
    "                model_out = dqn_model.forward(torch_x, 1, 1, hidden_state, cell_state)\n",
    "                out = model_out[0]\n",
    "                action = int(torch.argmax(out[0]))\n",
    "                hidden_state = model_out[1][0]\n",
    "                cell_state = model_out[1][1]\n",
    "            \n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            # env.render()\n",
    "            next_state = next_state[[0, 2]]\n",
    "            \n",
    "            rewards.append(reward)\n",
    "            \n",
    "            currrent_episode.append((prev_state, action, reward, next_state, done))\n",
    "            \n",
    "            prev_state = next_state            \n",
    "            \n",
    "            # Copy weights to the target network\n",
    "            if (t_total_steps % target_network_update_freq) == 0:\n",
    "                dqn_target.load_state_dict(dqn_model.state_dict())\n",
    "        \n",
    "            # Training\n",
    "            if (t_total_steps % train_freq) == 0:\n",
    "                batch = replay_buffer.sample(batch_size, episode_training_len)\n",
    "                loss = train_drqn_batch(optimizer, batch, episode_training_len, dqn_model, dqn_target, gamma)\n",
    "                losses.append(loss)\n",
    "\n",
    "            # Debugging\n",
    "            if t_total_steps % print_freq == 0:\n",
    "                logger.record_tabular(\"steps\", t_total_steps)\n",
    "                logger.record_tabular(\"episodes\", t_episode)\n",
    "                logger.record_tabular(\"short episodes\", short_episode_cnt)\n",
    "                logger.record_tabular(\"good episodes\", good_episode_cnt)\n",
    "\n",
    "                logger.record_tabular(\"mean reward\", np.mean(last_100ep_returns))\n",
    "                logger.record_tabular(\"mean len\", np.mean(last_100ep_lens))\n",
    "\n",
    "                logger.record_tabular(\"% time spent exploring\", int(100 * epsilon))\n",
    "                logger.dump_tabular()\n",
    "\n",
    "            # Saving models and losses\n",
    "            if t_total_steps % model_save_freq == 0:     \n",
    "                torch.save(dqn_model.state_dict(),'model_{}.torch'.format(t_total_steps))\n",
    "\n",
    "                with open(\"loss.pkl\", \"wb\") as fp:\n",
    "                    pickle.dump(losses, fp)    \n",
    "                \n",
    "            if done:\n",
    "                t_episode += 1\n",
    "\n",
    "                for i in range(len(rewards)):\n",
    "                    episode_return += rewards[i] * pow(gamma, i)\n",
    "\n",
    "                last_100ep_lens.append(len(currrent_episode))\n",
    "                last_100ep_returns.append(episode_return)\n",
    "                \n",
    "                break\n",
    "\n",
    "        if len(currrent_episode) >= episode_training_len:\n",
    "            replay_buffer.add_episode(currrent_episode)\n",
    "            good_episode_cnt += 1\n",
    "        else:\n",
    "            short_episode_cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to /home/hainh22/logs/28-12-2019/17:06:08/\n",
      "Done pre-populated with 100 episodes\n",
      "-------------------------------------\n",
      "| % time spent exploring | 99       |\n",
      "| episodes               | 4        |\n",
      "| good episodes          | 3        |\n",
      "| mean len               | 7.5      |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 3        |\n",
      "| steps                  | 100      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 98       |\n",
      "| episodes               | 6        |\n",
      "| good episodes          | 7        |\n",
      "| mean len               | 7        |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 4        |\n",
      "| steps                  | 200      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 97       |\n",
      "| episodes               | 8        |\n",
      "| good episodes          | 11       |\n",
      "| mean len               | 7.12     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 5        |\n",
      "| steps                  | 300      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 96       |\n",
      "| episodes               | 8        |\n",
      "| good episodes          | 14       |\n",
      "| mean len               | 7.12     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 5        |\n",
      "| steps                  | 400      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 95       |\n",
      "| episodes               | 10       |\n",
      "| good episodes          | 19       |\n",
      "| mean len               | 7.9      |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 5        |\n",
      "| steps                  | 500      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 94       |\n",
      "| episodes               | 10       |\n",
      "| good episodes          | 22       |\n",
      "| mean len               | 7.9      |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 5        |\n",
      "| steps                  | 600      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 93       |\n",
      "| episodes               | 13       |\n",
      "| good episodes          | 25       |\n",
      "| mean len               | 7.77     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 7        |\n",
      "| steps                  | 700      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 92       |\n",
      "| episodes               | 15       |\n",
      "| good episodes          | 29       |\n",
      "| mean len               | 8.8      |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 8        |\n",
      "| steps                  | 800      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 91       |\n",
      "| episodes               | 18       |\n",
      "| good episodes          | 32       |\n",
      "| mean len               | 8.83     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 10       |\n",
      "| steps                  | 900      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 90       |\n",
      "| episodes               | 18       |\n",
      "| good episodes          | 36       |\n",
      "| mean len               | 8.83     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 10       |\n",
      "| steps                  | 1e+03    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 89       |\n",
      "| episodes               | 22       |\n",
      "| good episodes          | 40       |\n",
      "| mean len               | 9.68     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 11       |\n",
      "| steps                  | 1.1e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 88       |\n",
      "| episodes               | 25       |\n",
      "| good episodes          | 43       |\n",
      "| mean len               | 10.8     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 12       |\n",
      "| steps                  | 1.2e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 87       |\n",
      "| episodes               | 25       |\n",
      "| good episodes          | 47       |\n",
      "| mean len               | 10.8     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 12       |\n",
      "| steps                  | 1.3e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 86       |\n",
      "| episodes               | 25       |\n",
      "| good episodes          | 50       |\n",
      "| mean len               | 10.8     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 12       |\n",
      "| steps                  | 1.4e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 85       |\n",
      "| episodes               | 27       |\n",
      "| good episodes          | 54       |\n",
      "| mean len               | 10.6     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 13       |\n",
      "| steps                  | 1.5e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 84       |\n",
      "| episodes               | 28       |\n",
      "| good episodes          | 58       |\n",
      "| mean len               | 10.7     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 13       |\n",
      "| steps                  | 1.6e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 83       |\n",
      "| episodes               | 29       |\n",
      "| good episodes          | 62       |\n",
      "| mean len               | 10.8     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 13       |\n",
      "| steps                  | 1.7e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 82       |\n",
      "| episodes               | 30       |\n",
      "| good episodes          | 65       |\n",
      "| mean len               | 11       |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 13       |\n",
      "| steps                  | 1.8e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 81       |\n",
      "| episodes               | 31       |\n",
      "| good episodes          | 69       |\n",
      "| mean len               | 10.7     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 14       |\n",
      "| steps                  | 1.9e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 80       |\n",
      "| episodes               | 31       |\n",
      "| good episodes          | 72       |\n",
      "| mean len               | 10.7     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 14       |\n",
      "| steps                  | 2e+03    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 79       |\n",
      "| episodes               | 32       |\n",
      "| good episodes          | 76       |\n",
      "| mean len               | 11.1     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 14       |\n",
      "| steps                  | 2.1e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 78       |\n",
      "| episodes               | 35       |\n",
      "| good episodes          | 80       |\n",
      "| mean len               | 11.4     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 15       |\n",
      "| steps                  | 2.2e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 77       |\n",
      "| episodes               | 37       |\n",
      "| good episodes          | 84       |\n",
      "| mean len               | 11.1     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 16       |\n",
      "| steps                  | 2.3e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 76       |\n",
      "| episodes               | 43       |\n",
      "| good episodes          | 86       |\n",
      "| mean len               | 9.88     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 22       |\n",
      "| steps                  | 2.4e+03  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| % time spent exploring | 75       |\n",
      "| episodes               | 43       |\n",
      "| good episodes          | 90       |\n",
      "| mean len               | 9.88     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 22       |\n",
      "| steps                  | 2.5e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 74       |\n",
      "| episodes               | 44       |\n",
      "| good episodes          | 93       |\n",
      "| mean len               | 9.8      |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 23       |\n",
      "| steps                  | 2.6e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 73       |\n",
      "| episodes               | 45       |\n",
      "| good episodes          | 97       |\n",
      "| mean len               | 9.89     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 23       |\n",
      "| steps                  | 2.7e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 72       |\n",
      "| episodes               | 45       |\n",
      "| good episodes          | 100      |\n",
      "| mean len               | 9.89     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 23       |\n",
      "| steps                  | 2.8e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 71       |\n",
      "| episodes               | 47       |\n",
      "| good episodes          | 104      |\n",
      "| mean len               | 9.83     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 24       |\n",
      "| steps                  | 2.9e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 70       |\n",
      "| episodes               | 47       |\n",
      "| good episodes          | 107      |\n",
      "| mean len               | 9.83     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 24       |\n",
      "| steps                  | 3e+03    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 69       |\n",
      "| episodes               | 47       |\n",
      "| good episodes          | 110      |\n",
      "| mean len               | 9.83     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 24       |\n",
      "| steps                  | 3.1e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 68       |\n",
      "| episodes               | 48       |\n",
      "| good episodes          | 114      |\n",
      "| mean len               | 9.96     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 24       |\n",
      "| steps                  | 3.2e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 67       |\n",
      "| episodes               | 48       |\n",
      "| good episodes          | 118      |\n",
      "| mean len               | 9.96     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 24       |\n",
      "| steps                  | 3.3e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 66       |\n",
      "| episodes               | 50       |\n",
      "| good episodes          | 121      |\n",
      "| mean len               | 9.86     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 25       |\n",
      "| steps                  | 3.4e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 65       |\n",
      "| episodes               | 52       |\n",
      "| good episodes          | 125      |\n",
      "| mean len               | 9.6      |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 27       |\n",
      "| steps                  | 3.5e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 64       |\n",
      "| episodes               | 54       |\n",
      "| good episodes          | 128      |\n",
      "| mean len               | 9.67     |\n",
      "| mean reward            | 0.0153   |\n",
      "| short episodes         | 28       |\n",
      "| steps                  | 3.6e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 63       |\n",
      "| episodes               | 55       |\n",
      "| good episodes          | 131      |\n",
      "| mean len               | 9.62     |\n",
      "| mean reward            | 0.015    |\n",
      "| short episodes         | 29       |\n",
      "| steps                  | 3.7e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 62       |\n",
      "| episodes               | 56       |\n",
      "| good episodes          | 135      |\n",
      "| mean len               | 9.64     |\n",
      "| mean reward            | 0.0148   |\n",
      "| short episodes         | 29       |\n",
      "| steps                  | 3.8e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 61       |\n",
      "| episodes               | 58       |\n",
      "| good episodes          | 138      |\n",
      "| mean len               | 9.48     |\n",
      "| mean reward            | 0.0142   |\n",
      "| short episodes         | 31       |\n",
      "| steps                  | 3.9e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 60       |\n",
      "| episodes               | 59       |\n",
      "| good episodes          | 142      |\n",
      "| mean len               | 9.49     |\n",
      "| mean reward            | 0.014    |\n",
      "| short episodes         | 31       |\n",
      "| steps                  | 4e+03    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 59       |\n",
      "| episodes               | 62       |\n",
      "| good episodes          | 146      |\n",
      "| mean len               | 9.32     |\n",
      "| mean reward            | 0.0133   |\n",
      "| short episodes         | 33       |\n",
      "| steps                  | 4.1e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 58       |\n",
      "| episodes               | 63       |\n",
      "| good episodes          | 149      |\n",
      "| mean len               | 9.22     |\n",
      "| mean reward            | 0.0131   |\n",
      "| short episodes         | 34       |\n",
      "| steps                  | 4.2e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 57       |\n",
      "| episodes               | 68       |\n",
      "| good episodes          | 155      |\n",
      "| mean len               | 9.41     |\n",
      "| mean reward            | 0.0121   |\n",
      "| short episodes         | 34       |\n",
      "| steps                  | 4.3e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 56       |\n",
      "| episodes               | 68       |\n",
      "| good episodes          | 159      |\n",
      "| mean len               | 9.41     |\n",
      "| mean reward            | 0.0121   |\n",
      "| short episodes         | 34       |\n",
      "| steps                  | 4.4e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 55       |\n",
      "| episodes               | 70       |\n",
      "| good episodes          | 163      |\n",
      "| mean len               | 9.37     |\n",
      "| mean reward            | 0.0245   |\n",
      "| short episodes         | 35       |\n",
      "| steps                  | 4.5e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 54       |\n",
      "| episodes               | 74       |\n",
      "| good episodes          | 166      |\n",
      "| mean len               | 9.18     |\n",
      "| mean reward            | 0.0231   |\n",
      "| short episodes         | 38       |\n",
      "| steps                  | 4.6e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 53       |\n",
      "| episodes               | 75       |\n",
      "| good episodes          | 169      |\n",
      "| mean len               | 9.09     |\n",
      "| mean reward            | 0.0228   |\n",
      "| short episodes         | 39       |\n",
      "| steps                  | 4.7e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 52       |\n",
      "| episodes               | 80       |\n",
      "| good episodes          | 174      |\n",
      "| mean len               | 9.3      |\n",
      "| mean reward            | 0.0326   |\n",
      "| short episodes         | 41       |\n",
      "| steps                  | 4.8e+03  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| % time spent exploring | 51       |\n",
      "| episodes               | 84       |\n",
      "| good episodes          | 177      |\n",
      "| mean len               | 9.2      |\n",
      "| mean reward            | 0.031    |\n",
      "| short episodes         | 44       |\n",
      "| steps                  | 4.9e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 50       |\n",
      "| episodes               | 89       |\n",
      "| good episodes          | 183      |\n",
      "| mean len               | 9.25     |\n",
      "| mean reward            | 0.0395   |\n",
      "| short episodes         | 45       |\n",
      "| steps                  | 5e+03    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 50       |\n",
      "| episodes               | 96       |\n",
      "| good episodes          | 186      |\n",
      "| mean len               | 9.16     |\n",
      "| mean reward            | 0.0366   |\n",
      "| short episodes         | 50       |\n",
      "| steps                  | 5.1e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 49       |\n",
      "| episodes               | 101      |\n",
      "| good episodes          | 190      |\n",
      "| mean len               | 8.97     |\n",
      "| mean reward            | 0.0351   |\n",
      "| short episodes         | 53       |\n",
      "| steps                  | 5.2e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 48       |\n",
      "| episodes               | 105      |\n",
      "| good episodes          | 195      |\n",
      "| mean len               | 9.09     |\n",
      "| mean reward            | 0.0439   |\n",
      "| short episodes         | 55       |\n",
      "| steps                  | 5.3e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 47       |\n",
      "| episodes               | 108      |\n",
      "| good episodes          | 199      |\n",
      "| mean len               | 9.17     |\n",
      "| mean reward            | 0.0439   |\n",
      "| short episodes         | 56       |\n",
      "| steps                  | 5.4e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 46       |\n",
      "| episodes               | 114      |\n",
      "| good episodes          | 203      |\n",
      "| mean len               | 9.22     |\n",
      "| mean reward            | 0.052    |\n",
      "| short episodes         | 60       |\n",
      "| steps                  | 5.5e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 45       |\n",
      "| episodes               | 116      |\n",
      "| good episodes          | 206      |\n",
      "| mean len               | 9.24     |\n",
      "| mean reward            | 0.052    |\n",
      "| short episodes         | 60       |\n",
      "| steps                  | 5.6e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 44       |\n",
      "| episodes               | 122      |\n",
      "| good episodes          | 211      |\n",
      "| mean len               | 8.96     |\n",
      "| mean reward            | 0.052    |\n",
      "| short episodes         | 64       |\n",
      "| steps                  | 5.7e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 43       |\n",
      "| episodes               | 132      |\n",
      "| good episodes          | 216      |\n",
      "| mean len               | 8.52     |\n",
      "| mean reward            | 0.0769   |\n",
      "| short episodes         | 69       |\n",
      "| steps                  | 5.8e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 42       |\n",
      "| episodes               | 136      |\n",
      "| good episodes          | 218      |\n",
      "| mean len               | 8.22     |\n",
      "| mean reward            | 0.0769   |\n",
      "| short episodes         | 73       |\n",
      "| steps                  | 5.9e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 41       |\n",
      "| episodes               | 137      |\n",
      "| good episodes          | 222      |\n",
      "| mean len               | 8.16     |\n",
      "| mean reward            | 0.0769   |\n",
      "| short episodes         | 74       |\n",
      "| steps                  | 6e+03    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 40       |\n",
      "| episodes               | 145      |\n",
      "| good episodes          | 226      |\n",
      "| mean len               | 8.24     |\n",
      "| mean reward            | 0.0769   |\n",
      "| short episodes         | 80       |\n",
      "| steps                  | 6.1e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 39       |\n",
      "| episodes               | 152      |\n",
      "| good episodes          | 230      |\n",
      "| mean len               | 8.23     |\n",
      "| mean reward            | 0.0857   |\n",
      "| short episodes         | 84       |\n",
      "| steps                  | 6.2e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 38       |\n",
      "| episodes               | 156      |\n",
      "| good episodes          | 235      |\n",
      "| mean len               | 8.07     |\n",
      "| mean reward            | 0.0774   |\n",
      "| short episodes         | 86       |\n",
      "| steps                  | 6.3e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 37       |\n",
      "| episodes               | 159      |\n",
      "| good episodes          | 239      |\n",
      "| mean len               | 8.27     |\n",
      "| mean reward            | 0.0774   |\n",
      "| short episodes         | 87       |\n",
      "| steps                  | 6.4e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 36       |\n",
      "| episodes               | 167      |\n",
      "| good episodes          | 242      |\n",
      "| mean len               | 7.9      |\n",
      "| mean reward            | 0.0866   |\n",
      "| short episodes         | 94       |\n",
      "| steps                  | 6.5e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 35       |\n",
      "| episodes               | 171      |\n",
      "| good episodes          | 245      |\n",
      "| mean len               | 7.79     |\n",
      "| mean reward            | 0.0778   |\n",
      "| short episodes         | 97       |\n",
      "| steps                  | 6.6e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 34       |\n",
      "| episodes               | 182      |\n",
      "| good episodes          | 250      |\n",
      "| mean len               | 7.7      |\n",
      "| mean reward            | 0.0863   |\n",
      "| short episodes         | 104      |\n",
      "| steps                  | 6.7e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 33       |\n",
      "| episodes               | 184      |\n",
      "| good episodes          | 253      |\n",
      "| mean len               | 7.58     |\n",
      "| mean reward            | 0.0863   |\n",
      "| short episodes         | 106      |\n",
      "| steps                  | 6.8e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 32       |\n",
      "| episodes               | 188      |\n",
      "| good episodes          | 258      |\n",
      "| mean len               | 7.8      |\n",
      "| mean reward            | 0.0941   |\n",
      "| short episodes         | 107      |\n",
      "| steps                  | 6.9e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 31       |\n",
      "| episodes               | 194      |\n",
      "| good episodes          | 262      |\n",
      "| mean len               | 7.7      |\n",
      "| mean reward            | 0.0941   |\n",
      "| short episodes         | 111      |\n",
      "| steps                  | 7e+03    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 30       |\n",
      "| episodes               | 200      |\n",
      "| good episodes          | 267      |\n",
      "| mean len               | 7.95     |\n",
      "| mean reward            | 0.0941   |\n",
      "| short episodes         | 112      |\n",
      "| steps                  | 7.1e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 29       |\n",
      "| episodes               | 209      |\n",
      "| good episodes          | 272      |\n",
      "| mean len               | 7.95     |\n",
      "| mean reward            | 0.0942   |\n",
      "| short episodes         | 117      |\n",
      "| steps                  | 7.2e+03  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| % time spent exploring | 28       |\n",
      "| episodes               | 214      |\n",
      "| good episodes          | 277      |\n",
      "| mean len               | 8.01     |\n",
      "| mean reward            | 0.103    |\n",
      "| short episodes         | 119      |\n",
      "| steps                  | 7.3e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 27       |\n",
      "| episodes               | 217      |\n",
      "| good episodes          | 282      |\n",
      "| mean len               | 7.83     |\n",
      "| mean reward            | 0.112    |\n",
      "| short episodes         | 119      |\n",
      "| steps                  | 7.4e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 26       |\n",
      "| episodes               | 226      |\n",
      "| good episodes          | 287      |\n",
      "| mean len               | 7.82     |\n",
      "| mean reward            | 0.112    |\n",
      "| short episodes         | 125      |\n",
      "| steps                  | 7.5e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 25       |\n",
      "| episodes               | 231      |\n",
      "| good episodes          | 291      |\n",
      "| mean len               | 7.63     |\n",
      "| mean reward            | 0.104    |\n",
      "| short episodes         | 128      |\n",
      "| steps                  | 7.6e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 24       |\n",
      "| episodes               | 235      |\n",
      "| good episodes          | 294      |\n",
      "| mean len               | 7.78     |\n",
      "| mean reward            | 0.104    |\n",
      "| short episodes         | 131      |\n",
      "| steps                  | 7.7e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 23       |\n",
      "| episodes               | 237      |\n",
      "| good episodes          | 297      |\n",
      "| mean len               | 7.86     |\n",
      "| mean reward            | 0.104    |\n",
      "| short episodes         | 132      |\n",
      "| steps                  | 7.8e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 22       |\n",
      "| episodes               | 241      |\n",
      "| good episodes          | 301      |\n",
      "| mean len               | 8.3      |\n",
      "| mean reward            | 0.112    |\n",
      "| short episodes         | 133      |\n",
      "| steps                  | 7.9e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 21       |\n",
      "| episodes               | 243      |\n",
      "| good episodes          | 304      |\n",
      "| mean len               | 8.34     |\n",
      "| mean reward            | 0.112    |\n",
      "| short episodes         | 135      |\n",
      "| steps                  | 8e+03    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 20       |\n",
      "| episodes               | 252      |\n",
      "| good episodes          | 310      |\n",
      "| mean len               | 8.3      |\n",
      "| mean reward            | 0.103    |\n",
      "| short episodes         | 140      |\n",
      "| steps                  | 8.1e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 19       |\n",
      "| episodes               | 258      |\n",
      "| good episodes          | 314      |\n",
      "| mean len               | 8.24     |\n",
      "| mean reward            | 0.103    |\n",
      "| short episodes         | 144      |\n",
      "| steps                  | 8.2e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 18       |\n",
      "| episodes               | 261      |\n",
      "| good episodes          | 318      |\n",
      "| mean len               | 8.39     |\n",
      "| mean reward            | 0.12     |\n",
      "| short episodes         | 145      |\n",
      "| steps                  | 8.3e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 17       |\n",
      "| episodes               | 265      |\n",
      "| good episodes          | 324      |\n",
      "| mean len               | 8.56     |\n",
      "| mean reward            | 0.111    |\n",
      "| short episodes         | 145      |\n",
      "| steps                  | 8.4e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 16       |\n",
      "| episodes               | 269      |\n",
      "| good episodes          | 327      |\n",
      "| mean len               | 8.71     |\n",
      "| mean reward            | 0.111    |\n",
      "| short episodes         | 148      |\n",
      "| steps                  | 8.5e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 15       |\n",
      "| episodes               | 273      |\n",
      "| good episodes          | 331      |\n",
      "| mean len               | 8.68     |\n",
      "| mean reward            | 0.111    |\n",
      "| short episodes         | 151      |\n",
      "| steps                  | 8.6e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 14       |\n",
      "| episodes               | 279      |\n",
      "| good episodes          | 334      |\n",
      "| mean len               | 8.64     |\n",
      "| mean reward            | 0.112    |\n",
      "| short episodes         | 156      |\n",
      "| steps                  | 8.7e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 13       |\n",
      "| episodes               | 281      |\n",
      "| good episodes          | 337      |\n",
      "| mean len               | 8.53     |\n",
      "| mean reward            | 0.112    |\n",
      "| short episodes         | 158      |\n",
      "| steps                  | 8.8e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 12       |\n",
      "| episodes               | 286      |\n",
      "| good episodes          | 341      |\n",
      "| mean len               | 8.34     |\n",
      "| mean reward            | 0.104    |\n",
      "| short episodes         | 161      |\n",
      "| steps                  | 8.9e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 11       |\n",
      "| episodes               | 289      |\n",
      "| good episodes          | 346      |\n",
      "| mean len               | 8.37     |\n",
      "| mean reward            | 0.104    |\n",
      "| short episodes         | 161      |\n",
      "| steps                  | 9e+03    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 10       |\n",
      "| episodes               | 292      |\n",
      "| good episodes          | 351      |\n",
      "| mean len               | 8.44     |\n",
      "| mean reward            | 0.113    |\n",
      "| short episodes         | 162      |\n",
      "| steps                  | 9.1e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 9        |\n",
      "| episodes               | 292      |\n",
      "| good episodes          | 354      |\n",
      "| mean len               | 8.44     |\n",
      "| mean reward            | 0.113    |\n",
      "| short episodes         | 162      |\n",
      "| steps                  | 9.2e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 8        |\n",
      "| episodes               | 297      |\n",
      "| good episodes          | 359      |\n",
      "| mean len               | 8.56     |\n",
      "| mean reward            | 0.13     |\n",
      "| short episodes         | 164      |\n",
      "| steps                  | 9.3e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 7        |\n",
      "| episodes               | 303      |\n",
      "| good episodes          | 363      |\n",
      "| mean len               | 8.34     |\n",
      "| mean reward            | 0.13     |\n",
      "| short episodes         | 168      |\n",
      "| steps                  | 9.4e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 6        |\n",
      "| episodes               | 310      |\n",
      "| good episodes          | 367      |\n",
      "| mean len               | 8.04     |\n",
      "| mean reward            | 0.139    |\n",
      "| short episodes         | 173      |\n",
      "| steps                  | 9.5e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 5        |\n",
      "| episodes               | 311      |\n",
      "| good episodes          | 371      |\n",
      "| mean len               | 8.07     |\n",
      "| mean reward            | 0.139    |\n",
      "| short episodes         | 173      |\n",
      "| steps                  | 9.6e+03  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| % time spent exploring | 4        |\n",
      "| episodes               | 314      |\n",
      "| good episodes          | 374      |\n",
      "| mean len               | 8.03     |\n",
      "| mean reward            | 0.131    |\n",
      "| short episodes         | 175      |\n",
      "| steps                  | 9.7e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 3        |\n",
      "| episodes               | 317      |\n",
      "| good episodes          | 379      |\n",
      "| mean len               | 7.91     |\n",
      "| mean reward            | 0.141    |\n",
      "| short episodes         | 176      |\n",
      "| steps                  | 9.8e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 322      |\n",
      "| good episodes          | 384      |\n",
      "| mean len               | 8.27     |\n",
      "| mean reward            | 0.159    |\n",
      "| short episodes         | 177      |\n",
      "| steps                  | 9.9e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 325      |\n",
      "| good episodes          | 388      |\n",
      "| mean len               | 8.28     |\n",
      "| mean reward            | 0.168    |\n",
      "| short episodes         | 179      |\n",
      "| steps                  | 1e+04    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 329      |\n",
      "| good episodes          | 392      |\n",
      "| mean len               | 8.19     |\n",
      "| mean reward            | 0.177    |\n",
      "| short episodes         | 181      |\n",
      "| steps                  | 1.01e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 331      |\n",
      "| good episodes          | 396      |\n",
      "| mean len               | 8.38     |\n",
      "| mean reward            | 0.177    |\n",
      "| short episodes         | 181      |\n",
      "| steps                  | 1.02e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 336      |\n",
      "| good episodes          | 400      |\n",
      "| mean len               | 8.12     |\n",
      "| mean reward            | 0.178    |\n",
      "| short episodes         | 185      |\n",
      "| steps                  | 1.03e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 340      |\n",
      "| good episodes          | 404      |\n",
      "| mean len               | 7.96     |\n",
      "| mean reward            | 0.187    |\n",
      "| short episodes         | 187      |\n",
      "| steps                  | 1.04e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 343      |\n",
      "| good episodes          | 408      |\n",
      "| mean len               | 8.02     |\n",
      "| mean reward            | 0.195    |\n",
      "| short episodes         | 188      |\n",
      "| steps                  | 1.05e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 346      |\n",
      "| good episodes          | 412      |\n",
      "| mean len               | 7.97     |\n",
      "| mean reward            | 0.195    |\n",
      "| short episodes         | 190      |\n",
      "| steps                  | 1.06e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 349      |\n",
      "| good episodes          | 415      |\n",
      "| mean len               | 8.28     |\n",
      "| mean reward            | 0.211    |\n",
      "| short episodes         | 191      |\n",
      "| steps                  | 1.07e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 352      |\n",
      "| good episodes          | 420      |\n",
      "| mean len               | 8.39     |\n",
      "| mean reward            | 0.229    |\n",
      "| short episodes         | 192      |\n",
      "| steps                  | 1.08e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 360      |\n",
      "| good episodes          | 426      |\n",
      "| mean len               | 8.58     |\n",
      "| mean reward            | 0.265    |\n",
      "| short episodes         | 194      |\n",
      "| steps                  | 1.09e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 361      |\n",
      "| good episodes          | 430      |\n",
      "| mean len               | 8.48     |\n",
      "| mean reward            | 0.266    |\n",
      "| short episodes         | 194      |\n",
      "| steps                  | 1.1e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 368      |\n",
      "| good episodes          | 435      |\n",
      "| mean len               | 8.48     |\n",
      "| mean reward            | 0.283    |\n",
      "| short episodes         | 198      |\n",
      "| steps                  | 1.11e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 373      |\n",
      "| good episodes          | 440      |\n",
      "| mean len               | 8.59     |\n",
      "| mean reward            | 0.292    |\n",
      "| short episodes         | 200      |\n",
      "| steps                  | 1.12e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 376      |\n",
      "| good episodes          | 444      |\n",
      "| mean len               | 8.77     |\n",
      "| mean reward            | 0.3      |\n",
      "| short episodes         | 201      |\n",
      "| steps                  | 1.13e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 385      |\n",
      "| good episodes          | 449      |\n",
      "| mean len               | 9.09     |\n",
      "| mean reward            | 0.335    |\n",
      "| short episodes         | 205      |\n",
      "| steps                  | 1.14e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 391      |\n",
      "| good episodes          | 454      |\n",
      "| mean len               | 9.03     |\n",
      "| mean reward            | 0.353    |\n",
      "| short episodes         | 208      |\n",
      "| steps                  | 1.15e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 394      |\n",
      "| good episodes          | 457      |\n",
      "| mean len               | 9.08     |\n",
      "| mean reward            | 0.352    |\n",
      "| short episodes         | 210      |\n",
      "| steps                  | 1.16e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 400      |\n",
      "| good episodes          | 462      |\n",
      "| mean len               | 8.82     |\n",
      "| mean reward            | 0.362    |\n",
      "| short episodes         | 214      |\n",
      "| steps                  | 1.17e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 404      |\n",
      "| good episodes          | 466      |\n",
      "| mean len               | 8.94     |\n",
      "| mean reward            | 0.361    |\n",
      "| short episodes         | 216      |\n",
      "| steps                  | 1.18e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 406      |\n",
      "| good episodes          | 470      |\n",
      "| mean len               | 8.9      |\n",
      "| mean reward            | 0.361    |\n",
      "| short episodes         | 217      |\n",
      "| steps                  | 1.19e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 409      |\n",
      "| good episodes          | 474      |\n",
      "| mean len               | 9.11     |\n",
      "| mean reward            | 0.37     |\n",
      "| short episodes         | 218      |\n",
      "| steps                  | 1.2e+04  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 413      |\n",
      "| good episodes          | 479      |\n",
      "| mean len               | 9.28     |\n",
      "| mean reward            | 0.379    |\n",
      "| short episodes         | 218      |\n",
      "| steps                  | 1.21e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 417      |\n",
      "| good episodes          | 483      |\n",
      "| mean len               | 9.28     |\n",
      "| mean reward            | 0.369    |\n",
      "| short episodes         | 221      |\n",
      "| steps                  | 1.22e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 418      |\n",
      "| good episodes          | 487      |\n",
      "| mean len               | 9.3      |\n",
      "| mean reward            | 0.369    |\n",
      "| short episodes         | 221      |\n",
      "| steps                  | 1.23e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 419      |\n",
      "| good episodes          | 490      |\n",
      "| mean len               | 9.35     |\n",
      "| mean reward            | 0.36     |\n",
      "| short episodes         | 221      |\n",
      "| steps                  | 1.24e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 422      |\n",
      "| good episodes          | 494      |\n",
      "| mean len               | 9.26     |\n",
      "| mean reward            | 0.368    |\n",
      "| short episodes         | 223      |\n",
      "| steps                  | 1.25e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 423      |\n",
      "| good episodes          | 498      |\n",
      "| mean len               | 9.35     |\n",
      "| mean reward            | 0.377    |\n",
      "| short episodes         | 223      |\n",
      "| steps                  | 1.26e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 429      |\n",
      "| good episodes          | 504      |\n",
      "| mean len               | 9.61     |\n",
      "| mean reward            | 0.376    |\n",
      "| short episodes         | 224      |\n",
      "| steps                  | 1.27e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 430      |\n",
      "| good episodes          | 507      |\n",
      "| mean len               | 9.74     |\n",
      "| mean reward            | 0.384    |\n",
      "| short episodes         | 224      |\n",
      "| steps                  | 1.28e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 433      |\n",
      "| good episodes          | 511      |\n",
      "| mean len               | 9.81     |\n",
      "| mean reward            | 0.393    |\n",
      "| short episodes         | 225      |\n",
      "| steps                  | 1.29e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 437      |\n",
      "| good episodes          | 514      |\n",
      "| mean len               | 9.91     |\n",
      "| mean reward            | 0.383    |\n",
      "| short episodes         | 228      |\n",
      "| steps                  | 1.3e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 444      |\n",
      "| good episodes          | 518      |\n",
      "| mean len               | 9.91     |\n",
      "| mean reward            | 0.366    |\n",
      "| short episodes         | 233      |\n",
      "| steps                  | 1.31e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 450      |\n",
      "| good episodes          | 522      |\n",
      "| mean len               | 9.86     |\n",
      "| mean reward            | 0.367    |\n",
      "| short episodes         | 236      |\n",
      "| steps                  | 1.32e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 455      |\n",
      "| good episodes          | 526      |\n",
      "| mean len               | 9.59     |\n",
      "| mean reward            | 0.323    |\n",
      "| short episodes         | 239      |\n",
      "| steps                  | 1.33e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 457      |\n",
      "| good episodes          | 530      |\n",
      "| mean len               | 9.45     |\n",
      "| mean reward            | 0.314    |\n",
      "| short episodes         | 240      |\n",
      "| steps                  | 1.34e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 463      |\n",
      "| good episodes          | 533      |\n",
      "| mean len               | 9.89     |\n",
      "| mean reward            | 0.312    |\n",
      "| short episodes         | 243      |\n",
      "| steps                  | 1.35e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 466      |\n",
      "| good episodes          | 539      |\n",
      "| mean len               | 9.89     |\n",
      "| mean reward            | 0.304    |\n",
      "| short episodes         | 243      |\n",
      "| steps                  | 1.36e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 469      |\n",
      "| good episodes          | 542      |\n",
      "| mean len               | 9.84     |\n",
      "| mean reward            | 0.312    |\n",
      "| short episodes         | 245      |\n",
      "| steps                  | 1.37e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 470      |\n",
      "| good episodes          | 545      |\n",
      "| mean len               | 9.84     |\n",
      "| mean reward            | 0.312    |\n",
      "| short episodes         | 246      |\n",
      "| steps                  | 1.38e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 474      |\n",
      "| good episodes          | 549      |\n",
      "| mean len               | 9.77     |\n",
      "| mean reward            | 0.286    |\n",
      "| short episodes         | 249      |\n",
      "| steps                  | 1.39e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 480      |\n",
      "| good episodes          | 552      |\n",
      "| mean len               | 10       |\n",
      "| mean reward            | 0.259    |\n",
      "| short episodes         | 252      |\n",
      "| steps                  | 1.4e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 487      |\n",
      "| good episodes          | 556      |\n",
      "| mean len               | 9.85     |\n",
      "| mean reward            | 0.224    |\n",
      "| short episodes         | 257      |\n",
      "| steps                  | 1.41e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 491      |\n",
      "| good episodes          | 561      |\n",
      "| mean len               | 9.99     |\n",
      "| mean reward            | 0.206    |\n",
      "| short episodes         | 258      |\n",
      "| steps                  | 1.42e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 492      |\n",
      "| good episodes          | 564      |\n",
      "| mean len               | 9.99     |\n",
      "| mean reward            | 0.206    |\n",
      "| short episodes         | 259      |\n",
      "| steps                  | 1.43e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 497      |\n",
      "| good episodes          | 568      |\n",
      "| mean len               | 9.99     |\n",
      "| mean reward            | 0.198    |\n",
      "| short episodes         | 262      |\n",
      "| steps                  | 1.44e+04 |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 500      |\n",
      "| good episodes          | 571      |\n",
      "| mean len               | 10.2     |\n",
      "| mean reward            | 0.189    |\n",
      "| short episodes         | 264      |\n",
      "| steps                  | 1.45e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 503      |\n",
      "| good episodes          | 574      |\n",
      "| mean len               | 9.91     |\n",
      "| mean reward            | 0.172    |\n",
      "| short episodes         | 267      |\n",
      "| steps                  | 1.46e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 509      |\n",
      "| good episodes          | 579      |\n",
      "| mean len               | 9.91     |\n",
      "| mean reward            | 0.172    |\n",
      "| short episodes         | 270      |\n",
      "| steps                  | 1.47e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 511      |\n",
      "| good episodes          | 582      |\n",
      "| mean len               | 9.88     |\n",
      "| mean reward            | 0.172    |\n",
      "| short episodes         | 271      |\n",
      "| steps                  | 1.48e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 512      |\n",
      "| good episodes          | 586      |\n",
      "| mean len               | 9.81     |\n",
      "| mean reward            | 0.172    |\n",
      "| short episodes         | 272      |\n",
      "| steps                  | 1.49e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 518      |\n",
      "| good episodes          | 590      |\n",
      "| mean len               | 9.74     |\n",
      "| mean reward            | 0.163    |\n",
      "| short episodes         | 275      |\n",
      "| steps                  | 1.5e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 520      |\n",
      "| good episodes          | 594      |\n",
      "| mean len               | 9.81     |\n",
      "| mean reward            | 0.171    |\n",
      "| short episodes         | 276      |\n",
      "| steps                  | 1.51e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 523      |\n",
      "| good episodes          | 597      |\n",
      "| mean len               | 9.78     |\n",
      "| mean reward            | 0.154    |\n",
      "| short episodes         | 278      |\n",
      "| steps                  | 1.52e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 527      |\n",
      "| good episodes          | 600      |\n",
      "| mean len               | 9.41     |\n",
      "| mean reward            | 0.128    |\n",
      "| short episodes         | 282      |\n",
      "| steps                  | 1.53e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 530      |\n",
      "| good episodes          | 603      |\n",
      "| mean len               | 9.17     |\n",
      "| mean reward            | 0.129    |\n",
      "| short episodes         | 284      |\n",
      "| steps                  | 1.54e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 532      |\n",
      "| good episodes          | 606      |\n",
      "| mean len               | 9.32     |\n",
      "| mean reward            | 0.127    |\n",
      "| short episodes         | 285      |\n",
      "| steps                  | 1.55e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 534      |\n",
      "| good episodes          | 610      |\n",
      "| mean len               | 9.23     |\n",
      "| mean reward            | 0.127    |\n",
      "| short episodes         | 287      |\n",
      "| steps                  | 1.56e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 536      |\n",
      "| good episodes          | 614      |\n",
      "| mean len               | 9.46     |\n",
      "| mean reward            | 0.127    |\n",
      "| short episodes         | 287      |\n",
      "| steps                  | 1.57e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 541      |\n",
      "| good episodes          | 617      |\n",
      "| mean len               | 9.22     |\n",
      "| mean reward            | 0.12     |\n",
      "| short episodes         | 291      |\n",
      "| steps                  | 1.58e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 544      |\n",
      "| good episodes          | 620      |\n",
      "| mean len               | 9.05     |\n",
      "| mean reward            | 0.12     |\n",
      "| short episodes         | 294      |\n",
      "| steps                  | 1.59e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 547      |\n",
      "| good episodes          | 624      |\n",
      "| mean len               | 9.01     |\n",
      "| mean reward            | 0.112    |\n",
      "| short episodes         | 295      |\n",
      "| steps                  | 1.6e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 549      |\n",
      "| good episodes          | 628      |\n",
      "| mean len               | 8.96     |\n",
      "| mean reward            | 0.111    |\n",
      "| short episodes         | 296      |\n",
      "| steps                  | 1.61e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 551      |\n",
      "| good episodes          | 631      |\n",
      "| mean len               | 8.92     |\n",
      "| mean reward            | 0.111    |\n",
      "| short episodes         | 298      |\n",
      "| steps                  | 1.62e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 553      |\n",
      "| good episodes          | 635      |\n",
      "| mean len               | 9.27     |\n",
      "| mean reward            | 0.111    |\n",
      "| short episodes         | 298      |\n",
      "| steps                  | 1.63e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 558      |\n",
      "| good episodes          | 637      |\n",
      "| mean len               | 9        |\n",
      "| mean reward            | 0.103    |\n",
      "| short episodes         | 303      |\n",
      "| steps                  | 1.64e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 559      |\n",
      "| good episodes          | 641      |\n",
      "| mean len               | 8.96     |\n",
      "| mean reward            | 0.103    |\n",
      "| short episodes         | 303      |\n",
      "| steps                  | 1.65e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 560      |\n",
      "| good episodes          | 645      |\n",
      "| mean len               | 9.16     |\n",
      "| mean reward            | 0.111    |\n",
      "| short episodes         | 303      |\n",
      "| steps                  | 1.66e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 561      |\n",
      "| good episodes          | 648      |\n",
      "| mean len               | 9.27     |\n",
      "| mean reward            | 0.119    |\n",
      "| short episodes         | 303      |\n",
      "| steps                  | 1.67e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 564      |\n",
      "| good episodes          | 653      |\n",
      "| mean len               | 9.11     |\n",
      "| mean reward            | 0.121    |\n",
      "| short episodes         | 304      |\n",
      "| steps                  | 1.68e+04 |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 570      |\n",
      "| good episodes          | 657      |\n",
      "| mean len               | 9.01     |\n",
      "| mean reward            | 0.112    |\n",
      "| short episodes         | 308      |\n",
      "| steps                  | 1.69e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 572      |\n",
      "| good episodes          | 660      |\n",
      "| mean len               | 8.81     |\n",
      "| mean reward            | 0.112    |\n",
      "| short episodes         | 310      |\n",
      "| steps                  | 1.7e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 574      |\n",
      "| good episodes          | 664      |\n",
      "| mean len               | 9.1      |\n",
      "| mean reward            | 0.12     |\n",
      "| short episodes         | 310      |\n",
      "| steps                  | 1.71e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 575      |\n",
      "| good episodes          | 667      |\n",
      "| mean len               | 9        |\n",
      "| mean reward            | 0.12     |\n",
      "| short episodes         | 311      |\n",
      "| steps                  | 1.72e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 578      |\n",
      "| good episodes          | 671      |\n",
      "| mean len               | 9.53     |\n",
      "| mean reward            | 0.12     |\n",
      "| short episodes         | 311      |\n",
      "| steps                  | 1.73e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 581      |\n",
      "| good episodes          | 675      |\n",
      "| mean len               | 9.28     |\n",
      "| mean reward            | 0.137    |\n",
      "| short episodes         | 312      |\n",
      "| steps                  | 1.74e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 587      |\n",
      "| good episodes          | 681      |\n",
      "| mean len               | 9.52     |\n",
      "| mean reward            | 0.146    |\n",
      "| short episodes         | 314      |\n",
      "| steps                  | 1.75e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 589      |\n",
      "| good episodes          | 685      |\n",
      "| mean len               | 9.58     |\n",
      "| mean reward            | 0.146    |\n",
      "| short episodes         | 314      |\n",
      "| steps                  | 1.76e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 591      |\n",
      "| good episodes          | 689      |\n",
      "| mean len               | 9.56     |\n",
      "| mean reward            | 0.155    |\n",
      "| short episodes         | 315      |\n",
      "| steps                  | 1.77e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 596      |\n",
      "| good episodes          | 695      |\n",
      "| mean len               | 9.73     |\n",
      "| mean reward            | 0.174    |\n",
      "| short episodes         | 315      |\n",
      "| steps                  | 1.78e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 599      |\n",
      "| good episodes          | 699      |\n",
      "| mean len               | 9.81     |\n",
      "| mean reward            | 0.183    |\n",
      "| short episodes         | 316      |\n",
      "| steps                  | 1.79e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 603      |\n",
      "| good episodes          | 703      |\n",
      "| mean len               | 10.4     |\n",
      "| mean reward            | 0.192    |\n",
      "| short episodes         | 317      |\n",
      "| steps                  | 1.8e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 606      |\n",
      "| good episodes          | 707      |\n",
      "| mean len               | 10.4     |\n",
      "| mean reward            | 0.183    |\n",
      "| short episodes         | 318      |\n",
      "| steps                  | 1.81e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 608      |\n",
      "| good episodes          | 710      |\n",
      "| mean len               | 10.6     |\n",
      "| mean reward            | 0.183    |\n",
      "| short episodes         | 319      |\n",
      "| steps                  | 1.82e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 611      |\n",
      "| good episodes          | 714      |\n",
      "| mean len               | 10.6     |\n",
      "| mean reward            | 0.183    |\n",
      "| short episodes         | 321      |\n",
      "| steps                  | 1.83e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 613      |\n",
      "| good episodes          | 717      |\n",
      "| mean len               | 10.4     |\n",
      "| mean reward            | 0.174    |\n",
      "| short episodes         | 323      |\n",
      "| steps                  | 1.84e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 617      |\n",
      "| good episodes          | 721      |\n",
      "| mean len               | 10.5     |\n",
      "| mean reward            | 0.165    |\n",
      "| short episodes         | 325      |\n",
      "| steps                  | 1.85e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 619      |\n",
      "| good episodes          | 724      |\n",
      "| mean len               | 10.3     |\n",
      "| mean reward            | 0.157    |\n",
      "| short episodes         | 327      |\n",
      "| steps                  | 1.86e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 619      |\n",
      "| good episodes          | 727      |\n",
      "| mean len               | 10.3     |\n",
      "| mean reward            | 0.157    |\n",
      "| short episodes         | 327      |\n",
      "| steps                  | 1.87e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 622      |\n",
      "| good episodes          | 731      |\n",
      "| mean len               | 10.3     |\n",
      "| mean reward            | 0.157    |\n",
      "| short episodes         | 329      |\n",
      "| steps                  | 1.88e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 624      |\n",
      "| good episodes          | 734      |\n",
      "| mean len               | 10.5     |\n",
      "| mean reward            | 0.157    |\n",
      "| short episodes         | 330      |\n",
      "| steps                  | 1.89e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 626      |\n",
      "| good episodes          | 738      |\n",
      "| mean len               | 10.9     |\n",
      "| mean reward            | 0.157    |\n",
      "| short episodes         | 330      |\n",
      "| steps                  | 1.9e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 628      |\n",
      "| good episodes          | 741      |\n",
      "| mean len               | 11       |\n",
      "| mean reward            | 0.157    |\n",
      "| short episodes         | 332      |\n",
      "| steps                  | 1.91e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 630      |\n",
      "| good episodes          | 744      |\n",
      "| mean len               | 11.1     |\n",
      "| mean reward            | 0.149    |\n",
      "| short episodes         | 333      |\n",
      "| steps                  | 1.92e+04 |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 632      |\n",
      "| good episodes          | 747      |\n",
      "| mean len               | 10.8     |\n",
      "| mean reward            | 0.141    |\n",
      "| short episodes         | 335      |\n",
      "| steps                  | 1.93e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 635      |\n",
      "| good episodes          | 751      |\n",
      "| mean len               | 11.1     |\n",
      "| mean reward            | 0.15     |\n",
      "| short episodes         | 335      |\n",
      "| steps                  | 1.94e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 641      |\n",
      "| good episodes          | 755      |\n",
      "| mean len               | 11.2     |\n",
      "| mean reward            | 0.15     |\n",
      "| short episodes         | 339      |\n",
      "| steps                  | 1.95e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 642      |\n",
      "| good episodes          | 758      |\n",
      "| mean len               | 11.2     |\n",
      "| mean reward            | 0.15     |\n",
      "| short episodes         | 340      |\n",
      "| steps                  | 1.96e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 644      |\n",
      "| good episodes          | 762      |\n",
      "| mean len               | 11.3     |\n",
      "| mean reward            | 0.159    |\n",
      "| short episodes         | 341      |\n",
      "| steps                  | 1.97e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 647      |\n",
      "| good episodes          | 765      |\n",
      "| mean len               | 11.2     |\n",
      "| mean reward            | 0.167    |\n",
      "| short episodes         | 343      |\n",
      "| steps                  | 1.98e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 650      |\n",
      "| good episodes          | 769      |\n",
      "| mean len               | 11.2     |\n",
      "| mean reward            | 0.158    |\n",
      "| short episodes         | 345      |\n",
      "| steps                  | 1.99e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 651      |\n",
      "| good episodes          | 772      |\n",
      "| mean len               | 11.2     |\n",
      "| mean reward            | 0.158    |\n",
      "| short episodes         | 346      |\n",
      "| steps                  | 2e+04    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 655      |\n",
      "| good episodes          | 776      |\n",
      "| mean len               | 10.9     |\n",
      "| mean reward            | 0.158    |\n",
      "| short episodes         | 349      |\n",
      "| steps                  | 2.01e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 657      |\n",
      "| good episodes          | 779      |\n",
      "| mean len               | 10.9     |\n",
      "| mean reward            | 0.158    |\n",
      "| short episodes         | 351      |\n",
      "| steps                  | 2.02e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 659      |\n",
      "| good episodes          | 783      |\n",
      "| mean len               | 10.8     |\n",
      "| mean reward            | 0.167    |\n",
      "| short episodes         | 352      |\n",
      "| steps                  | 2.03e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 663      |\n",
      "| good episodes          | 785      |\n",
      "| mean len               | 10.4     |\n",
      "| mean reward            | 0.151    |\n",
      "| short episodes         | 356      |\n",
      "| steps                  | 2.04e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 665      |\n",
      "| good episodes          | 789      |\n",
      "| mean len               | 10.6     |\n",
      "| mean reward            | 0.142    |\n",
      "| short episodes         | 357      |\n",
      "| steps                  | 2.05e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 669      |\n",
      "| good episodes          | 793      |\n",
      "| mean len               | 10.7     |\n",
      "| mean reward            | 0.142    |\n",
      "| short episodes         | 359      |\n",
      "| steps                  | 2.06e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 671      |\n",
      "| good episodes          | 796      |\n",
      "| mean len               | 10.7     |\n",
      "| mean reward            | 0.142    |\n",
      "| short episodes         | 361      |\n",
      "| steps                  | 2.07e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 675      |\n",
      "| good episodes          | 799      |\n",
      "| mean len               | 10.5     |\n",
      "| mean reward            | 0.133    |\n",
      "| short episodes         | 364      |\n",
      "| steps                  | 2.08e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 679      |\n",
      "| good episodes          | 802      |\n",
      "| mean len               | 10.3     |\n",
      "| mean reward            | 0.133    |\n",
      "| short episodes         | 367      |\n",
      "| steps                  | 2.09e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 681      |\n",
      "| good episodes          | 806      |\n",
      "| mean len               | 10       |\n",
      "| mean reward            | 0.117    |\n",
      "| short episodes         | 368      |\n",
      "| steps                  | 2.1e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 687      |\n",
      "| good episodes          | 809      |\n",
      "| mean len               | 9.91     |\n",
      "| mean reward            | 0.107    |\n",
      "| short episodes         | 373      |\n",
      "| steps                  | 2.11e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 687      |\n",
      "| good episodes          | 812      |\n",
      "| mean len               | 9.91     |\n",
      "| mean reward            | 0.107    |\n",
      "| short episodes         | 373      |\n",
      "| steps                  | 2.12e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 690      |\n",
      "| good episodes          | 816      |\n",
      "| mean len               | 9.88     |\n",
      "| mean reward            | 0.0984   |\n",
      "| short episodes         | 374      |\n",
      "| steps                  | 2.13e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 693      |\n",
      "| good episodes          | 819      |\n",
      "| mean len               | 9.9      |\n",
      "| mean reward            | 0.0891   |\n",
      "| short episodes         | 376      |\n",
      "| steps                  | 2.14e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 696      |\n",
      "| good episodes          | 822      |\n",
      "| mean len               | 9.69     |\n",
      "| mean reward            | 0.0707   |\n",
      "| short episodes         | 379      |\n",
      "| steps                  | 2.15e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 703      |\n",
      "| good episodes          | 825      |\n",
      "| mean len               | 8.84     |\n",
      "| mean reward            | 0.0526   |\n",
      "| short episodes         | 385      |\n",
      "| steps                  | 2.16e+04 |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 703      |\n",
      "| good episodes          | 829      |\n",
      "| mean len               | 8.84     |\n",
      "| mean reward            | 0.0526   |\n",
      "| short episodes         | 385      |\n",
      "| steps                  | 2.17e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 705      |\n",
      "| good episodes          | 832      |\n",
      "| mean len               | 9.01     |\n",
      "| mean reward            | 0.0526   |\n",
      "| short episodes         | 386      |\n",
      "| steps                  | 2.18e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 707      |\n",
      "| good episodes          | 836      |\n",
      "| mean len               | 8.78     |\n",
      "| mean reward            | 0.0439   |\n",
      "| short episodes         | 387      |\n",
      "| steps                  | 2.19e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 712      |\n",
      "| good episodes          | 840      |\n",
      "| mean len               | 8.69     |\n",
      "| mean reward            | 0.0439   |\n",
      "| short episodes         | 390      |\n",
      "| steps                  | 2.2e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 713      |\n",
      "| good episodes          | 844      |\n",
      "| mean len               | 8.77     |\n",
      "| mean reward            | 0.0439   |\n",
      "| short episodes         | 390      |\n",
      "| steps                  | 2.21e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 719      |\n",
      "| good episodes          | 848      |\n",
      "| mean len               | 8.84     |\n",
      "| mean reward            | 0.0439   |\n",
      "| short episodes         | 394      |\n",
      "| steps                  | 2.22e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 721      |\n",
      "| good episodes          | 851      |\n",
      "| mean len               | 8.8      |\n",
      "| mean reward            | 0.0439   |\n",
      "| short episodes         | 395      |\n",
      "| steps                  | 2.23e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 725      |\n",
      "| good episodes          | 856      |\n",
      "| mean len               | 8.76     |\n",
      "| mean reward            | 0.0532   |\n",
      "| short episodes         | 396      |\n",
      "| steps                  | 2.24e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 729      |\n",
      "| good episodes          | 858      |\n",
      "| mean len               | 8.25     |\n",
      "| mean reward            | 0.0532   |\n",
      "| short episodes         | 400      |\n",
      "| steps                  | 2.25e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 734      |\n",
      "| good episodes          | 862      |\n",
      "| mean len               | 8.15     |\n",
      "| mean reward            | 0.0443   |\n",
      "| short episodes         | 404      |\n",
      "| steps                  | 2.26e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 735      |\n",
      "| good episodes          | 865      |\n",
      "| mean len               | 8.11     |\n",
      "| mean reward            | 0.0443   |\n",
      "| short episodes         | 404      |\n",
      "| steps                  | 2.27e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 740      |\n",
      "| good episodes          | 868      |\n",
      "| mean len               | 7.96     |\n",
      "| mean reward            | 0.0443   |\n",
      "| short episodes         | 409      |\n",
      "| steps                  | 2.28e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 742      |\n",
      "| good episodes          | 871      |\n",
      "| mean len               | 7.79     |\n",
      "| mean reward            | 0.0443   |\n",
      "| short episodes         | 411      |\n",
      "| steps                  | 2.29e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 747      |\n",
      "| good episodes          | 874      |\n",
      "| mean len               | 7.56     |\n",
      "| mean reward            | 0.0274   |\n",
      "| short episodes         | 416      |\n",
      "| steps                  | 2.3e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 751      |\n",
      "| good episodes          | 877      |\n",
      "| mean len               | 7.4      |\n",
      "| mean reward            | 0.0274   |\n",
      "| short episodes         | 420      |\n",
      "| steps                  | 2.31e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 754      |\n",
      "| good episodes          | 880      |\n",
      "| mean len               | 7.41     |\n",
      "| mean reward            | 0.0274   |\n",
      "| short episodes         | 422      |\n",
      "| steps                  | 2.32e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 756      |\n",
      "| good episodes          | 883      |\n",
      "| mean len               | 7.4      |\n",
      "| mean reward            | 0.0274   |\n",
      "| short episodes         | 424      |\n",
      "| steps                  | 2.33e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 757      |\n",
      "| good episodes          | 887      |\n",
      "| mean len               | 7.42     |\n",
      "| mean reward            | 0.0274   |\n",
      "| short episodes         | 425      |\n",
      "| steps                  | 2.34e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 761      |\n",
      "| good episodes          | 890      |\n",
      "| mean len               | 7.69     |\n",
      "| mean reward            | 0.0184   |\n",
      "| short episodes         | 427      |\n",
      "| steps                  | 2.35e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 763      |\n",
      "| good episodes          | 894      |\n",
      "| mean len               | 7.86     |\n",
      "| mean reward            | 0.0184   |\n",
      "| short episodes         | 428      |\n",
      "| steps                  | 2.36e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 766      |\n",
      "| good episodes          | 897      |\n",
      "| mean len               | 7.47     |\n",
      "| mean reward            | 0.0184   |\n",
      "| short episodes         | 431      |\n",
      "| steps                  | 2.37e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 767      |\n",
      "| good episodes          | 901      |\n",
      "| mean len               | 7.52     |\n",
      "| mean reward            | 0.0184   |\n",
      "| short episodes         | 431      |\n",
      "| steps                  | 2.38e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 771      |\n",
      "| good episodes          | 903      |\n",
      "| mean len               | 7.45     |\n",
      "| mean reward            | 0.00932  |\n",
      "| short episodes         | 435      |\n",
      "| steps                  | 2.39e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 782      |\n",
      "| good episodes          | 908      |\n",
      "| mean len               | 6.94     |\n",
      "| mean reward            | 0.0279   |\n",
      "| short episodes         | 443      |\n",
      "| steps                  | 2.4e+04  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 783      |\n",
      "| good episodes          | 911      |\n",
      "| mean len               | 6.97     |\n",
      "| mean reward            | 0.0279   |\n",
      "| short episodes         | 444      |\n",
      "| steps                  | 2.41e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 786      |\n",
      "| good episodes          | 915      |\n",
      "| mean len               | 7.28     |\n",
      "| mean reward            | 0.0279   |\n",
      "| short episodes         | 445      |\n",
      "| steps                  | 2.42e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 787      |\n",
      "| good episodes          | 918      |\n",
      "| mean len               | 7.24     |\n",
      "| mean reward            | 0.0279   |\n",
      "| short episodes         | 446      |\n",
      "| steps                  | 2.43e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 790      |\n",
      "| good episodes          | 922      |\n",
      "| mean len               | 6.91     |\n",
      "| mean reward            | 0.0279   |\n",
      "| short episodes         | 448      |\n",
      "| steps                  | 2.44e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 794      |\n",
      "| good episodes          | 925      |\n",
      "| mean len               | 6.87     |\n",
      "| mean reward            | 0.0279   |\n",
      "| short episodes         | 451      |\n",
      "| steps                  | 2.45e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 796      |\n",
      "| good episodes          | 929      |\n",
      "| mean len               | 7.02     |\n",
      "| mean reward            | 0.0279   |\n",
      "| short episodes         | 452      |\n",
      "| steps                  | 2.46e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 798      |\n",
      "| good episodes          | 933      |\n",
      "| mean len               | 7.09     |\n",
      "| mean reward            | 0.0279   |\n",
      "| short episodes         | 453      |\n",
      "| steps                  | 2.47e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 803      |\n",
      "| good episodes          | 937      |\n",
      "| mean len               | 7.32     |\n",
      "| mean reward            | 0.0366   |\n",
      "| short episodes         | 456      |\n",
      "| steps                  | 2.48e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 805      |\n",
      "| good episodes          | 940      |\n",
      "| mean len               | 7.56     |\n",
      "| mean reward            | 0.0366   |\n",
      "| short episodes         | 456      |\n",
      "| steps                  | 2.49e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 808      |\n",
      "| good episodes          | 944      |\n",
      "| mean len               | 7.59     |\n",
      "| mean reward            | 0.0366   |\n",
      "| short episodes         | 457      |\n",
      "| steps                  | 2.5e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 814      |\n",
      "| good episodes          | 948      |\n",
      "| mean len               | 7.39     |\n",
      "| mean reward            | 0.0454   |\n",
      "| short episodes         | 462      |\n",
      "| steps                  | 2.51e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 817      |\n",
      "| good episodes          | 950      |\n",
      "| mean len               | 7.68     |\n",
      "| mean reward            | 0.0454   |\n",
      "| short episodes         | 464      |\n",
      "| steps                  | 2.52e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 820      |\n",
      "| good episodes          | 953      |\n",
      "| mean len               | 7.66     |\n",
      "| mean reward            | 0.0454   |\n",
      "| short episodes         | 467      |\n",
      "| steps                  | 2.53e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 821      |\n",
      "| good episodes          | 956      |\n",
      "| mean len               | 7.48     |\n",
      "| mean reward            | 0.0454   |\n",
      "| short episodes         | 468      |\n",
      "| steps                  | 2.54e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 827      |\n",
      "| good episodes          | 961      |\n",
      "| mean len               | 7.44     |\n",
      "| mean reward            | 0.0533   |\n",
      "| short episodes         | 471      |\n",
      "| steps                  | 2.55e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 831      |\n",
      "| good episodes          | 964      |\n",
      "| mean len               | 7.27     |\n",
      "| mean reward            | 0.0533   |\n",
      "| short episodes         | 475      |\n",
      "| steps                  | 2.56e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 835      |\n",
      "| good episodes          | 967      |\n",
      "| mean len               | 7.58     |\n",
      "| mean reward            | 0.0533   |\n",
      "| short episodes         | 477      |\n",
      "| steps                  | 2.57e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 841      |\n",
      "| good episodes          | 971      |\n",
      "| mean len               | 8.03     |\n",
      "| mean reward            | 0.0533   |\n",
      "| short episodes         | 480      |\n",
      "| steps                  | 2.58e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 841      |\n",
      "| good episodes          | 975      |\n",
      "| mean len               | 8.03     |\n",
      "| mean reward            | 0.0533   |\n",
      "| short episodes         | 480      |\n",
      "| steps                  | 2.59e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 848      |\n",
      "| good episodes          | 977      |\n",
      "| mean len               | 8.24     |\n",
      "| mean reward            | 0.0533   |\n",
      "| short episodes         | 486      |\n",
      "| steps                  | 2.6e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 852      |\n",
      "| good episodes          | 980      |\n",
      "| mean len               | 8.18     |\n",
      "| mean reward            | 0.0533   |\n",
      "| short episodes         | 490      |\n",
      "| steps                  | 2.61e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 857      |\n",
      "| good episodes          | 983      |\n",
      "| mean len               | 8.36     |\n",
      "| mean reward            | 0.0533   |\n",
      "| short episodes         | 494      |\n",
      "| steps                  | 2.62e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 857      |\n",
      "| good episodes          | 986      |\n",
      "| mean len               | 8.36     |\n",
      "| mean reward            | 0.0533   |\n",
      "| short episodes         | 494      |\n",
      "| steps                  | 2.63e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 859      |\n",
      "| good episodes          | 990      |\n",
      "| mean len               | 8.41     |\n",
      "| mean reward            | 0.0533   |\n",
      "| short episodes         | 495      |\n",
      "| steps                  | 2.64e+04 |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 859      |\n",
      "| good episodes          | 993      |\n",
      "| mean len               | 8.41     |\n",
      "| mean reward            | 0.0533   |\n",
      "| short episodes         | 495      |\n",
      "| steps                  | 2.65e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 864      |\n",
      "| good episodes          | 996      |\n",
      "| mean len               | 8.2      |\n",
      "| mean reward            | 0.062    |\n",
      "| short episodes         | 499      |\n",
      "| steps                  | 2.66e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 868      |\n",
      "| good episodes          | 1e+03    |\n",
      "| mean len               | 8.19     |\n",
      "| mean reward            | 0.062    |\n",
      "| short episodes         | 502      |\n",
      "| steps                  | 2.67e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 871      |\n",
      "| good episodes          | 1e+03    |\n",
      "| mean len               | 8.27     |\n",
      "| mean reward            | 0.062    |\n",
      "| short episodes         | 504      |\n",
      "| steps                  | 2.68e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 873      |\n",
      "| good episodes          | 1.01e+03 |\n",
      "| mean len               | 8.21     |\n",
      "| mean reward            | 0.0528   |\n",
      "| short episodes         | 506      |\n",
      "| steps                  | 2.69e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 875      |\n",
      "| good episodes          | 1.01e+03 |\n",
      "| mean len               | 8.12     |\n",
      "| mean reward            | 0.0528   |\n",
      "| short episodes         | 508      |\n",
      "| steps                  | 2.7e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 876      |\n",
      "| good episodes          | 1.01e+03 |\n",
      "| mean len               | 8.22     |\n",
      "| mean reward            | 0.0528   |\n",
      "| short episodes         | 508      |\n",
      "| steps                  | 2.71e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 877      |\n",
      "| good episodes          | 1.02e+03 |\n",
      "| mean len               | 8.36     |\n",
      "| mean reward            | 0.0613   |\n",
      "| short episodes         | 508      |\n",
      "| steps                  | 2.72e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 881      |\n",
      "| good episodes          | 1.02e+03 |\n",
      "| mean len               | 8.37     |\n",
      "| mean reward            | 0.052    |\n",
      "| short episodes         | 512      |\n",
      "| steps                  | 2.73e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 882      |\n",
      "| good episodes          | 1.02e+03 |\n",
      "| mean len               | 8.36     |\n",
      "| mean reward            | 0.052    |\n",
      "| short episodes         | 513      |\n",
      "| steps                  | 2.74e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 886      |\n",
      "| good episodes          | 1.03e+03 |\n",
      "| mean len               | 8.43     |\n",
      "| mean reward            | 0.0609   |\n",
      "| short episodes         | 514      |\n",
      "| steps                  | 2.75e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 887      |\n",
      "| good episodes          | 1.03e+03 |\n",
      "| mean len               | 8.55     |\n",
      "| mean reward            | 0.0609   |\n",
      "| short episodes         | 514      |\n",
      "| steps                  | 2.76e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 891      |\n",
      "| good episodes          | 1.03e+03 |\n",
      "| mean len               | 8.55     |\n",
      "| mean reward            | 0.0609   |\n",
      "| short episodes         | 518      |\n",
      "| steps                  | 2.77e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 896      |\n",
      "| good episodes          | 1.04e+03 |\n",
      "| mean len               | 8.45     |\n",
      "| mean reward            | 0.07     |\n",
      "| short episodes         | 521      |\n",
      "| steps                  | 2.78e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 897      |\n",
      "| good episodes          | 1.04e+03 |\n",
      "| mean len               | 8.43     |\n",
      "| mean reward            | 0.07     |\n",
      "| short episodes         | 522      |\n",
      "| steps                  | 2.79e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 904      |\n",
      "| good episodes          | 1.04e+03 |\n",
      "| mean len               | 8.15     |\n",
      "| mean reward            | 0.0612   |\n",
      "| short episodes         | 527      |\n",
      "| steps                  | 2.8e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 908      |\n",
      "| good episodes          | 1.05e+03 |\n",
      "| mean len               | 7.87     |\n",
      "| mean reward            | 0.0612   |\n",
      "| short episodes         | 529      |\n",
      "| steps                  | 2.81e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 912      |\n",
      "| good episodes          | 1.05e+03 |\n",
      "| mean len               | 8.33     |\n",
      "| mean reward            | 0.0599   |\n",
      "| short episodes         | 531      |\n",
      "| steps                  | 2.82e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 919      |\n",
      "| good episodes          | 1.06e+03 |\n",
      "| mean len               | 8.2      |\n",
      "| mean reward            | 0.0599   |\n",
      "| short episodes         | 537      |\n",
      "| steps                  | 2.83e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 920      |\n",
      "| good episodes          | 1.06e+03 |\n",
      "| mean len               | 8.42     |\n",
      "| mean reward            | 0.0599   |\n",
      "| short episodes         | 537      |\n",
      "| steps                  | 2.84e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 922      |\n",
      "| good episodes          | 1.06e+03 |\n",
      "| mean len               | 8.43     |\n",
      "| mean reward            | 0.0599   |\n",
      "| short episodes         | 539      |\n",
      "| steps                  | 2.85e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 927      |\n",
      "| good episodes          | 1.06e+03 |\n",
      "| mean len               | 8.22     |\n",
      "| mean reward            | 0.0427   |\n",
      "| short episodes         | 543      |\n",
      "| steps                  | 2.86e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 930      |\n",
      "| good episodes          | 1.07e+03 |\n",
      "| mean len               | 8.48     |\n",
      "| mean reward            | 0.0427   |\n",
      "| short episodes         | 545      |\n",
      "| steps                  | 2.87e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 932      |\n",
      "| good episodes          | 1.07e+03 |\n",
      "| mean len               | 8.58     |\n",
      "| mean reward            | 0.0505   |\n",
      "| short episodes         | 545      |\n",
      "| steps                  | 2.88e+04 |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 938      |\n",
      "| good episodes          | 1.08e+03 |\n",
      "| mean len               | 8.26     |\n",
      "| mean reward            | 0.0505   |\n",
      "| short episodes         | 550      |\n",
      "| steps                  | 2.89e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 942      |\n",
      "| good episodes          | 1.08e+03 |\n",
      "| mean len               | 8.33     |\n",
      "| mean reward            | 0.0505   |\n",
      "| short episodes         | 552      |\n",
      "| steps                  | 2.9e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 945      |\n",
      "| good episodes          | 1.08e+03 |\n",
      "| mean len               | 8.41     |\n",
      "| mean reward            | 0.0505   |\n",
      "| short episodes         | 553      |\n",
      "| steps                  | 2.91e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 948      |\n",
      "| good episodes          | 1.09e+03 |\n",
      "| mean len               | 8.71     |\n",
      "| mean reward            | 0.0505   |\n",
      "| short episodes         | 554      |\n",
      "| steps                  | 2.92e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 953      |\n",
      "| good episodes          | 1.09e+03 |\n",
      "| mean len               | 8.63     |\n",
      "| mean reward            | 0.0505   |\n",
      "| short episodes         | 558      |\n",
      "| steps                  | 2.93e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 956      |\n",
      "| good episodes          | 1.09e+03 |\n",
      "| mean len               | 8.77     |\n",
      "| mean reward            | 0.0505   |\n",
      "| short episodes         | 560      |\n",
      "| steps                  | 2.94e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 958      |\n",
      "| good episodes          | 1.1e+03  |\n",
      "| mean len               | 8.52     |\n",
      "| mean reward            | 0.0505   |\n",
      "| short episodes         | 562      |\n",
      "| steps                  | 2.95e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 963      |\n",
      "| good episodes          | 1.1e+03  |\n",
      "| mean len               | 8.58     |\n",
      "| mean reward            | 0.0418   |\n",
      "| short episodes         | 566      |\n",
      "| steps                  | 2.96e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 970      |\n",
      "| good episodes          | 1.1e+03  |\n",
      "| mean len               | 8.69     |\n",
      "| mean reward            | 0.0418   |\n",
      "| short episodes         | 571      |\n",
      "| steps                  | 2.97e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 971      |\n",
      "| good episodes          | 1.11e+03 |\n",
      "| mean len               | 8.7      |\n",
      "| mean reward            | 0.0418   |\n",
      "| short episodes         | 572      |\n",
      "| steps                  | 2.98e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 972      |\n",
      "| good episodes          | 1.11e+03 |\n",
      "| mean len               | 8.72     |\n",
      "| mean reward            | 0.0418   |\n",
      "| short episodes         | 573      |\n",
      "| steps                  | 2.99e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 976      |\n",
      "| good episodes          | 1.11e+03 |\n",
      "| mean len               | 8.87     |\n",
      "| mean reward            | 0.0418   |\n",
      "| short episodes         | 575      |\n",
      "| steps                  | 3e+04    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 979      |\n",
      "| good episodes          | 1.12e+03 |\n",
      "| mean len               | 8.74     |\n",
      "| mean reward            | 0.0333   |\n",
      "| short episodes         | 578      |\n",
      "| steps                  | 3.01e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 982      |\n",
      "| good episodes          | 1.12e+03 |\n",
      "| mean len               | 9.14     |\n",
      "| mean reward            | 0.0333   |\n",
      "| short episodes         | 579      |\n",
      "| steps                  | 3.02e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 984      |\n",
      "| good episodes          | 1.12e+03 |\n",
      "| mean len               | 9.2      |\n",
      "| mean reward            | 0.0328   |\n",
      "| short episodes         | 580      |\n",
      "| steps                  | 3.03e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 987      |\n",
      "| good episodes          | 1.13e+03 |\n",
      "| mean len               | 8.69     |\n",
      "| mean reward            | 0.0328   |\n",
      "| short episodes         | 583      |\n",
      "| steps                  | 3.04e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 993      |\n",
      "| good episodes          | 1.13e+03 |\n",
      "| mean len               | 8.91     |\n",
      "| mean reward            | 0.0238   |\n",
      "| short episodes         | 588      |\n",
      "| steps                  | 3.05e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 998      |\n",
      "| good episodes          | 1.13e+03 |\n",
      "| mean len               | 8.82     |\n",
      "| mean reward            | 0.0238   |\n",
      "| short episodes         | 592      |\n",
      "| steps                  | 3.06e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1e+03    |\n",
      "| good episodes          | 1.14e+03 |\n",
      "| mean len               | 9.18     |\n",
      "| mean reward            | 0.0238   |\n",
      "| short episodes         | 592      |\n",
      "| steps                  | 3.07e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1e+03    |\n",
      "| good episodes          | 1.14e+03 |\n",
      "| mean len               | 9.32     |\n",
      "| mean reward            | 0.0238   |\n",
      "| short episodes         | 592      |\n",
      "| steps                  | 3.08e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.01e+03 |\n",
      "| good episodes          | 1.14e+03 |\n",
      "| mean len               | 8.76     |\n",
      "| mean reward            | 0.0163   |\n",
      "| short episodes         | 600      |\n",
      "| steps                  | 3.09e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.02e+03 |\n",
      "| good episodes          | 1.15e+03 |\n",
      "| mean len               | 8.29     |\n",
      "| mean reward            | 0.0163   |\n",
      "| short episodes         | 608      |\n",
      "| steps                  | 3.1e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.02e+03 |\n",
      "| good episodes          | 1.15e+03 |\n",
      "| mean len               | 8.24     |\n",
      "| mean reward            | 0.0163   |\n",
      "| short episodes         | 610      |\n",
      "| steps                  | 3.11e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.02e+03 |\n",
      "| good episodes          | 1.15e+03 |\n",
      "| mean len               | 8.62     |\n",
      "| mean reward            | 0.0163   |\n",
      "| short episodes         | 610      |\n",
      "| steps                  | 3.12e+04 |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.02e+03 |\n",
      "| good episodes          | 1.16e+03 |\n",
      "| mean len               | 8.62     |\n",
      "| mean reward            | 0.0163   |\n",
      "| short episodes         | 610      |\n",
      "| steps                  | 3.13e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.02e+03 |\n",
      "| good episodes          | 1.16e+03 |\n",
      "| mean len               | 8.61     |\n",
      "| mean reward            | 0.0163   |\n",
      "| short episodes         | 612      |\n",
      "| steps                  | 3.14e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.03e+03 |\n",
      "| good episodes          | 1.16e+03 |\n",
      "| mean len               | 8.47     |\n",
      "| mean reward            | 0.0163   |\n",
      "| short episodes         | 614      |\n",
      "| steps                  | 3.15e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.03e+03 |\n",
      "| good episodes          | 1.17e+03 |\n",
      "| mean len               | 8.47     |\n",
      "| mean reward            | 0.0163   |\n",
      "| short episodes         | 614      |\n",
      "| steps                  | 3.16e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.03e+03 |\n",
      "| good episodes          | 1.17e+03 |\n",
      "| mean len               | 8.42     |\n",
      "| mean reward            | 0.0163   |\n",
      "| short episodes         | 616      |\n",
      "| steps                  | 3.17e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.03e+03 |\n",
      "| good episodes          | 1.17e+03 |\n",
      "| mean len               | 8.42     |\n",
      "| mean reward            | 0.0163   |\n",
      "| short episodes         | 616      |\n",
      "| steps                  | 3.18e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.03e+03 |\n",
      "| good episodes          | 1.18e+03 |\n",
      "| mean len               | 8.33     |\n",
      "| mean reward            | 0.00843  |\n",
      "| short episodes         | 616      |\n",
      "| steps                  | 3.19e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.03e+03 |\n",
      "| good episodes          | 1.18e+03 |\n",
      "| mean len               | 8.21     |\n",
      "| mean reward            | 0.00843  |\n",
      "| short episodes         | 617      |\n",
      "| steps                  | 3.2e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.03e+03 |\n",
      "| good episodes          | 1.18e+03 |\n",
      "| mean len               | 8.45     |\n",
      "| mean reward            | 0.00843  |\n",
      "| short episodes         | 617      |\n",
      "| steps                  | 3.21e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.04e+03 |\n",
      "| good episodes          | 1.19e+03 |\n",
      "| mean len               | 8.28     |\n",
      "| mean reward            | 0.00843  |\n",
      "| short episodes         | 623      |\n",
      "| steps                  | 3.22e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.04e+03 |\n",
      "| good episodes          | 1.19e+03 |\n",
      "| mean len               | 7.93     |\n",
      "| mean reward            | 0.00843  |\n",
      "| short episodes         | 628      |\n",
      "| steps                  | 3.23e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.05e+03 |\n",
      "| good episodes          | 1.19e+03 |\n",
      "| mean len               | 7.63     |\n",
      "| mean reward            | 0.00843  |\n",
      "| short episodes         | 631      |\n",
      "| steps                  | 3.24e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.05e+03 |\n",
      "| good episodes          | 1.19e+03 |\n",
      "| mean len               | 7.48     |\n",
      "| mean reward            | 0.00843  |\n",
      "| short episodes         | 632      |\n",
      "| steps                  | 3.25e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.05e+03 |\n",
      "| good episodes          | 1.2e+03  |\n",
      "| mean len               | 7.46     |\n",
      "| mean reward            | 0.00843  |\n",
      "| short episodes         | 635      |\n",
      "| steps                  | 3.26e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.06e+03 |\n",
      "| good episodes          | 1.2e+03  |\n",
      "| mean len               | 7.37     |\n",
      "| mean reward            | 0.00843  |\n",
      "| short episodes         | 639      |\n",
      "| steps                  | 3.27e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.06e+03 |\n",
      "| good episodes          | 1.2e+03  |\n",
      "| mean len               | 7.57     |\n",
      "| mean reward            | 0.00843  |\n",
      "| short episodes         | 639      |\n",
      "| steps                  | 3.28e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.06e+03 |\n",
      "| good episodes          | 1.21e+03 |\n",
      "| mean len               | 7.51     |\n",
      "| mean reward            | 0.00843  |\n",
      "| short episodes         | 643      |\n",
      "| steps                  | 3.29e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.07e+03 |\n",
      "| good episodes          | 1.21e+03 |\n",
      "| mean len               | 7.28     |\n",
      "| mean reward            | 0.00843  |\n",
      "| short episodes         | 646      |\n",
      "| steps                  | 3.3e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.07e+03 |\n",
      "| good episodes          | 1.22e+03 |\n",
      "| mean len               | 7.28     |\n",
      "| mean reward            | 0.00843  |\n",
      "| short episodes         | 648      |\n",
      "| steps                  | 3.31e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.07e+03 |\n",
      "| good episodes          | 1.22e+03 |\n",
      "| mean len               | 7.26     |\n",
      "| mean reward            | 0.00843  |\n",
      "| short episodes         | 651      |\n",
      "| steps                  | 3.32e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.07e+03 |\n",
      "| good episodes          | 1.22e+03 |\n",
      "| mean len               | 7.21     |\n",
      "| mean reward            | 0.00843  |\n",
      "| short episodes         | 653      |\n",
      "| steps                  | 3.33e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.08e+03 |\n",
      "| good episodes          | 1.22e+03 |\n",
      "| mean len               | 7.36     |\n",
      "| mean reward            | 0.00843  |\n",
      "| short episodes         | 655      |\n",
      "| steps                  | 3.34e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.08e+03 |\n",
      "| good episodes          | 1.23e+03 |\n",
      "| mean len               | 7.14     |\n",
      "| mean reward            | 0.00843  |\n",
      "| short episodes         | 658      |\n",
      "| steps                  | 3.35e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.09e+03 |\n",
      "| good episodes          | 1.23e+03 |\n",
      "| mean len               | 7.38     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 660      |\n",
      "| steps                  | 3.36e+04 |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.09e+03 |\n",
      "| good episodes          | 1.23e+03 |\n",
      "| mean len               | 7.38     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 660      |\n",
      "| steps                  | 3.37e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.09e+03 |\n",
      "| good episodes          | 1.24e+03 |\n",
      "| mean len               | 7.54     |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 664      |\n",
      "| steps                  | 3.38e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.09e+03 |\n",
      "| good episodes          | 1.24e+03 |\n",
      "| mean len               | 7.3      |\n",
      "| mean reward            | 0        |\n",
      "| short episodes         | 666      |\n",
      "| steps                  | 3.39e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.09e+03 |\n",
      "| good episodes          | 1.24e+03 |\n",
      "| mean len               | 7.38     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 666      |\n",
      "| steps                  | 3.4e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.1e+03  |\n",
      "| good episodes          | 1.25e+03 |\n",
      "| mean len               | 7.4      |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 669      |\n",
      "| steps                  | 3.41e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.1e+03  |\n",
      "| good episodes          | 1.25e+03 |\n",
      "| mean len               | 6.86     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 673      |\n",
      "| steps                  | 3.42e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.1e+03  |\n",
      "| good episodes          | 1.25e+03 |\n",
      "| mean len               | 6.86     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 675      |\n",
      "| steps                  | 3.43e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.11e+03 |\n",
      "| good episodes          | 1.26e+03 |\n",
      "| mean len               | 6.87     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 679      |\n",
      "| steps                  | 3.44e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.11e+03 |\n",
      "| good episodes          | 1.26e+03 |\n",
      "| mean len               | 6.97     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 681      |\n",
      "| steps                  | 3.45e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.11e+03 |\n",
      "| good episodes          | 1.26e+03 |\n",
      "| mean len               | 6.97     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 681      |\n",
      "| steps                  | 3.46e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.11e+03 |\n",
      "| good episodes          | 1.27e+03 |\n",
      "| mean len               | 6.97     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 682      |\n",
      "| steps                  | 3.47e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.11e+03 |\n",
      "| good episodes          | 1.27e+03 |\n",
      "| mean len               | 7.2      |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 684      |\n",
      "| steps                  | 3.48e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.11e+03 |\n",
      "| good episodes          | 1.27e+03 |\n",
      "| mean len               | 7.2      |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 684      |\n",
      "| steps                  | 3.49e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.12e+03 |\n",
      "| good episodes          | 1.28e+03 |\n",
      "| mean len               | 7.19     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 685      |\n",
      "| steps                  | 3.5e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.12e+03 |\n",
      "| good episodes          | 1.28e+03 |\n",
      "| mean len               | 7.19     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 685      |\n",
      "| steps                  | 3.51e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.12e+03 |\n",
      "| good episodes          | 1.28e+03 |\n",
      "| mean len               | 7.21     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 685      |\n",
      "| steps                  | 3.52e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.12e+03 |\n",
      "| good episodes          | 1.29e+03 |\n",
      "| mean len               | 7.35     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 686      |\n",
      "| steps                  | 3.53e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.12e+03 |\n",
      "| good episodes          | 1.29e+03 |\n",
      "| mean len               | 6.99     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 690      |\n",
      "| steps                  | 3.54e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.12e+03 |\n",
      "| good episodes          | 1.29e+03 |\n",
      "| mean len               | 6.74     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 691      |\n",
      "| steps                  | 3.55e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.12e+03 |\n",
      "| good episodes          | 1.3e+03  |\n",
      "| mean len               | 6.83     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 691      |\n",
      "| steps                  | 3.56e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.13e+03 |\n",
      "| good episodes          | 1.3e+03  |\n",
      "| mean len               | 6.88     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 694      |\n",
      "| steps                  | 3.57e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.13e+03 |\n",
      "| good episodes          | 1.3e+03  |\n",
      "| mean len               | 6.82     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 696      |\n",
      "| steps                  | 3.58e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.13e+03 |\n",
      "| good episodes          | 1.31e+03 |\n",
      "| mean len               | 6.82     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 696      |\n",
      "| steps                  | 3.59e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.13e+03 |\n",
      "| good episodes          | 1.31e+03 |\n",
      "| mean len               | 6.7      |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 697      |\n",
      "| steps                  | 3.6e+04  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.13e+03 |\n",
      "| good episodes          | 1.31e+03 |\n",
      "| mean len               | 6.33     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 700      |\n",
      "| steps                  | 3.61e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.14e+03 |\n",
      "| good episodes          | 1.32e+03 |\n",
      "| mean len               | 6.31     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 702      |\n",
      "| steps                  | 3.62e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.14e+03 |\n",
      "| good episodes          | 1.32e+03 |\n",
      "| mean len               | 6.29     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 703      |\n",
      "| steps                  | 3.63e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.14e+03 |\n",
      "| good episodes          | 1.32e+03 |\n",
      "| mean len               | 6.28     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 704      |\n",
      "| steps                  | 3.64e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.14e+03 |\n",
      "| good episodes          | 1.32e+03 |\n",
      "| mean len               | 6.48     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 707      |\n",
      "| steps                  | 3.65e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.14e+03 |\n",
      "| good episodes          | 1.33e+03 |\n",
      "| mean len               | 6.68     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 708      |\n",
      "| steps                  | 3.66e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.14e+03 |\n",
      "| good episodes          | 1.33e+03 |\n",
      "| mean len               | 6.69     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 709      |\n",
      "| steps                  | 3.67e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.15e+03 |\n",
      "| good episodes          | 1.33e+03 |\n",
      "| mean len               | 6.68     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 712      |\n",
      "| steps                  | 3.68e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.15e+03 |\n",
      "| good episodes          | 1.34e+03 |\n",
      "| mean len               | 6.68     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 714      |\n",
      "| steps                  | 3.69e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.15e+03 |\n",
      "| good episodes          | 1.34e+03 |\n",
      "| mean len               | 6.7      |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 717      |\n",
      "| steps                  | 3.7e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.15e+03 |\n",
      "| good episodes          | 1.34e+03 |\n",
      "| mean len               | 6.74     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 718      |\n",
      "| steps                  | 3.71e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.16e+03 |\n",
      "| good episodes          | 1.35e+03 |\n",
      "| mean len               | 7.02     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 719      |\n",
      "| steps                  | 3.72e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.16e+03 |\n",
      "| good episodes          | 1.35e+03 |\n",
      "| mean len               | 6.83     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 723      |\n",
      "| steps                  | 3.73e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.16e+03 |\n",
      "| good episodes          | 1.35e+03 |\n",
      "| mean len               | 6.9      |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 725      |\n",
      "| steps                  | 3.74e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.17e+03 |\n",
      "| good episodes          | 1.36e+03 |\n",
      "| mean len               | 6.92     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 727      |\n",
      "| steps                  | 3.75e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.17e+03 |\n",
      "| good episodes          | 1.36e+03 |\n",
      "| mean len               | 6.92     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 727      |\n",
      "| steps                  | 3.76e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.17e+03 |\n",
      "| good episodes          | 1.36e+03 |\n",
      "| mean len               | 6.92     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 727      |\n",
      "| steps                  | 3.77e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.17e+03 |\n",
      "| good episodes          | 1.37e+03 |\n",
      "| mean len               | 6.98     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 730      |\n",
      "| steps                  | 3.78e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.17e+03 |\n",
      "| good episodes          | 1.37e+03 |\n",
      "| mean len               | 6.97     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 731      |\n",
      "| steps                  | 3.79e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.17e+03 |\n",
      "| good episodes          | 1.37e+03 |\n",
      "| mean len               | 7.03     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 733      |\n",
      "| steps                  | 3.8e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.18e+03 |\n",
      "| good episodes          | 1.38e+03 |\n",
      "| mean len               | 7.08     |\n",
      "| mean reward            | 0.0176   |\n",
      "| short episodes         | 736      |\n",
      "| steps                  | 3.81e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.18e+03 |\n",
      "| good episodes          | 1.38e+03 |\n",
      "| mean len               | 6.86     |\n",
      "| mean reward            | 0.0176   |\n",
      "| short episodes         | 738      |\n",
      "| steps                  | 3.82e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.19e+03 |\n",
      "| good episodes          | 1.38e+03 |\n",
      "| mean len               | 6.48     |\n",
      "| mean reward            | 0.0176   |\n",
      "| short episodes         | 743      |\n",
      "| steps                  | 3.83e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.19e+03 |\n",
      "| good episodes          | 1.39e+03 |\n",
      "| mean len               | 6.3      |\n",
      "| mean reward            | 0.0176   |\n",
      "| short episodes         | 746      |\n",
      "| steps                  | 3.84e+04 |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.19e+03 |\n",
      "| good episodes          | 1.39e+03 |\n",
      "| mean len               | 6.28     |\n",
      "| mean reward            | 0.0176   |\n",
      "| short episodes         | 749      |\n",
      "| steps                  | 3.85e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.19e+03 |\n",
      "| good episodes          | 1.39e+03 |\n",
      "| mean len               | 6.25     |\n",
      "| mean reward            | 0.0176   |\n",
      "| short episodes         | 750      |\n",
      "| steps                  | 3.86e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.2e+03  |\n",
      "| good episodes          | 1.4e+03  |\n",
      "| mean len               | 6.1      |\n",
      "| mean reward            | 0.00886  |\n",
      "| short episodes         | 754      |\n",
      "| steps                  | 3.87e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.2e+03  |\n",
      "| good episodes          | 1.4e+03  |\n",
      "| mean len               | 6.1      |\n",
      "| mean reward            | 0.00886  |\n",
      "| short episodes         | 760      |\n",
      "| steps                  | 3.88e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.20e+03 |\n",
      "| good episodes          | 1.4e+03  |\n",
      "| mean len               | 6.15     |\n",
      "| mean reward            | 0.00886  |\n",
      "| short episodes         | 762      |\n",
      "| steps                  | 3.89e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.21e+03 |\n",
      "| good episodes          | 1.4e+03  |\n",
      "| mean len               | 6.04     |\n",
      "| mean reward            | 0.00886  |\n",
      "| short episodes         | 765      |\n",
      "| steps                  | 3.9e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.21e+03 |\n",
      "| good episodes          | 1.41e+03 |\n",
      "| mean len               | 5.92     |\n",
      "| mean reward            | 0.00886  |\n",
      "| short episodes         | 768      |\n",
      "| steps                  | 3.91e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.22e+03 |\n",
      "| good episodes          | 1.41e+03 |\n",
      "| mean len               | 5.96     |\n",
      "| mean reward            | 0.00886  |\n",
      "| short episodes         | 771      |\n",
      "| steps                  | 3.92e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.22e+03 |\n",
      "| good episodes          | 1.41e+03 |\n",
      "| mean len               | 6.04     |\n",
      "| mean reward            | 0.0169   |\n",
      "| short episodes         | 772      |\n",
      "| steps                  | 3.93e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.22e+03 |\n",
      "| good episodes          | 1.42e+03 |\n",
      "| mean len               | 6.09     |\n",
      "| mean reward            | 0.0169   |\n",
      "| short episodes         | 772      |\n",
      "| steps                  | 3.94e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.22e+03 |\n",
      "| good episodes          | 1.42e+03 |\n",
      "| mean len               | 6.23     |\n",
      "| mean reward            | 0.0259   |\n",
      "| short episodes         | 775      |\n",
      "| steps                  | 3.95e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.23e+03 |\n",
      "| good episodes          | 1.42e+03 |\n",
      "| mean len               | 5.91     |\n",
      "| mean reward            | 0.0259   |\n",
      "| short episodes         | 781      |\n",
      "| steps                  | 3.96e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.24e+03 |\n",
      "| good episodes          | 1.43e+03 |\n",
      "| mean len               | 5.98     |\n",
      "| mean reward            | 0.0259   |\n",
      "| short episodes         | 788      |\n",
      "| steps                  | 3.97e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.24e+03 |\n",
      "| good episodes          | 1.43e+03 |\n",
      "| mean len               | 6.03     |\n",
      "| mean reward            | 0.0259   |\n",
      "| short episodes         | 790      |\n",
      "| steps                  | 3.98e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.24e+03 |\n",
      "| good episodes          | 1.43e+03 |\n",
      "| mean len               | 5.66     |\n",
      "| mean reward            | 0.0259   |\n",
      "| short episodes         | 795      |\n",
      "| steps                  | 3.99e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.24e+03 |\n",
      "| good episodes          | 1.44e+03 |\n",
      "| mean len               | 5.66     |\n",
      "| mean reward            | 0.0259   |\n",
      "| short episodes         | 796      |\n",
      "| steps                  | 4e+04    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.25e+03 |\n",
      "| good episodes          | 1.44e+03 |\n",
      "| mean len               | 5.67     |\n",
      "| mean reward            | 0.0259   |\n",
      "| short episodes         | 800      |\n",
      "| steps                  | 4.01e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.25e+03 |\n",
      "| good episodes          | 1.44e+03 |\n",
      "| mean len               | 5.67     |\n",
      "| mean reward            | 0.0259   |\n",
      "| short episodes         | 804      |\n",
      "| steps                  | 4.02e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.26e+03 |\n",
      "| good episodes          | 1.44e+03 |\n",
      "| mean len               | 5.7      |\n",
      "| mean reward            | 0.0259   |\n",
      "| short episodes         | 806      |\n",
      "| steps                  | 4.03e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.26e+03 |\n",
      "| good episodes          | 1.45e+03 |\n",
      "| mean len               | 5.65     |\n",
      "| mean reward            | 0.0347   |\n",
      "| short episodes         | 810      |\n",
      "| steps                  | 4.04e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.26e+03 |\n",
      "| good episodes          | 1.45e+03 |\n",
      "| mean len               | 5.53     |\n",
      "| mean reward            | 0.0347   |\n",
      "| short episodes         | 812      |\n",
      "| steps                  | 4.05e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.26e+03 |\n",
      "| good episodes          | 1.46e+03 |\n",
      "| mean len               | 5.53     |\n",
      "| mean reward            | 0.0347   |\n",
      "| short episodes         | 812      |\n",
      "| steps                  | 4.06e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.27e+03 |\n",
      "| good episodes          | 1.46e+03 |\n",
      "| mean len               | 5.46     |\n",
      "| mean reward            | 0.0347   |\n",
      "| short episodes         | 816      |\n",
      "| steps                  | 4.07e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.27e+03 |\n",
      "| good episodes          | 1.46e+03 |\n",
      "| mean len               | 5.41     |\n",
      "| mean reward            | 0.0347   |\n",
      "| short episodes         | 820      |\n",
      "| steps                  | 4.08e+04 |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.27e+03 |\n",
      "| good episodes          | 1.46e+03 |\n",
      "| mean len               | 5.41     |\n",
      "| mean reward            | 0.0347   |\n",
      "| short episodes         | 820      |\n",
      "| steps                  | 4.09e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.27e+03 |\n",
      "| good episodes          | 1.47e+03 |\n",
      "| mean len               | 5.47     |\n",
      "| mean reward            | 0.0347   |\n",
      "| short episodes         | 821      |\n",
      "| steps                  | 4.1e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.28e+03 |\n",
      "| good episodes          | 1.47e+03 |\n",
      "| mean len               | 5.37     |\n",
      "| mean reward            | 0.0258   |\n",
      "| short episodes         | 824      |\n",
      "| steps                  | 4.11e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.28e+03 |\n",
      "| good episodes          | 1.47e+03 |\n",
      "| mean len               | 5.4      |\n",
      "| mean reward            | 0.0258   |\n",
      "| short episodes         | 827      |\n",
      "| steps                  | 4.12e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.28e+03 |\n",
      "| good episodes          | 1.48e+03 |\n",
      "| mean len               | 5.39     |\n",
      "| mean reward            | 0.0258   |\n",
      "| short episodes         | 828      |\n",
      "| steps                  | 4.13e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.29e+03 |\n",
      "| good episodes          | 1.48e+03 |\n",
      "| mean len               | 5.5      |\n",
      "| mean reward            | 0.0258   |\n",
      "| short episodes         | 833      |\n",
      "| steps                  | 4.14e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.29e+03 |\n",
      "| good episodes          | 1.48e+03 |\n",
      "| mean len               | 5.52     |\n",
      "| mean reward            | 0.0258   |\n",
      "| short episodes         | 835      |\n",
      "| steps                  | 4.15e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.29e+03 |\n",
      "| good episodes          | 1.49e+03 |\n",
      "| mean len               | 5.81     |\n",
      "| mean reward            | 0.0258   |\n",
      "| short episodes         | 835      |\n",
      "| steps                  | 4.16e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.29e+03 |\n",
      "| good episodes          | 1.49e+03 |\n",
      "| mean len               | 6.06     |\n",
      "| mean reward            | 0.0258   |\n",
      "| short episodes         | 835      |\n",
      "| steps                  | 4.17e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.3e+03  |\n",
      "| good episodes          | 1.49e+03 |\n",
      "| mean len               | 6.14     |\n",
      "| mean reward            | 0.0258   |\n",
      "| short episodes         | 838      |\n",
      "| steps                  | 4.18e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.3e+03  |\n",
      "| good episodes          | 1.5e+03  |\n",
      "| mean len               | 6.38     |\n",
      "| mean reward            | 0.0258   |\n",
      "| short episodes         | 840      |\n",
      "| steps                  | 4.19e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.3e+03  |\n",
      "| good episodes          | 1.5e+03  |\n",
      "| mean len               | 6.6      |\n",
      "| mean reward            | 0.0258   |\n",
      "| short episodes         | 841      |\n",
      "| steps                  | 4.2e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.3e+03  |\n",
      "| good episodes          | 1.5e+03  |\n",
      "| mean len               | 6.61     |\n",
      "| mean reward            | 0.0258   |\n",
      "| short episodes         | 844      |\n",
      "| steps                  | 4.21e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.30e+03 |\n",
      "| good episodes          | 1.51e+03 |\n",
      "| mean len               | 6.62     |\n",
      "| mean reward            | 0.0258   |\n",
      "| short episodes         | 845      |\n",
      "| steps                  | 4.22e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.31e+03 |\n",
      "| good episodes          | 1.51e+03 |\n",
      "| mean len               | 6.55     |\n",
      "| mean reward            | 0.0258   |\n",
      "| short episodes         | 851      |\n",
      "| steps                  | 4.23e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.32e+03 |\n",
      "| good episodes          | 1.51e+03 |\n",
      "| mean len               | 6.48     |\n",
      "| mean reward            | 0.0258   |\n",
      "| short episodes         | 855      |\n",
      "| steps                  | 4.24e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.32e+03 |\n",
      "| good episodes          | 1.51e+03 |\n",
      "| mean len               | 6.48     |\n",
      "| mean reward            | 0.0258   |\n",
      "| short episodes         | 855      |\n",
      "| steps                  | 4.25e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.32e+03 |\n",
      "| good episodes          | 1.52e+03 |\n",
      "| mean len               | 6.15     |\n",
      "| mean reward            | 0.0178   |\n",
      "| short episodes         | 858      |\n",
      "| steps                  | 4.26e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.32e+03 |\n",
      "| good episodes          | 1.52e+03 |\n",
      "| mean len               | 6.04     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 860      |\n",
      "| steps                  | 4.27e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.32e+03 |\n",
      "| good episodes          | 1.52e+03 |\n",
      "| mean len               | 6.06     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 863      |\n",
      "| steps                  | 4.28e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.33e+03 |\n",
      "| good episodes          | 1.53e+03 |\n",
      "| mean len               | 6.3      |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 865      |\n",
      "| steps                  | 4.29e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.33e+03 |\n",
      "| good episodes          | 1.53e+03 |\n",
      "| mean len               | 6.3      |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 869      |\n",
      "| steps                  | 4.3e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.33e+03 |\n",
      "| good episodes          | 1.53e+03 |\n",
      "| mean len               | 6.32     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 871      |\n",
      "| steps                  | 4.31e+04 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.34e+03 |\n",
      "| good episodes          | 1.54e+03 |\n",
      "| mean len               | 6.67     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 873      |\n",
      "| steps                  | 4.32e+04 |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| % time spent exploring | 2        |\n",
      "| episodes               | 1.34e+03 |\n",
      "| good episodes          | 1.54e+03 |\n",
      "| mean len               | 6.66     |\n",
      "| mean reward            | 0.00878  |\n",
      "| short episodes         | 875      |\n",
      "| steps                  | 4.33e+04 |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num_timesteps = 100000\n",
    "env=\"TwoBumps-v1\"\n",
    "seed = 0\n",
    "final_epsilon = 0.02\n",
    "exploration_fraction = 0.1\n",
    "replay_size = 50000\n",
    "batch_size = 32\n",
    "target_network_update_freq = 500\n",
    "num_prepopulate_episode = 100\n",
    "print_freq = 100\n",
    "model_save_freq = 10000\n",
    "train_freq = 1\n",
    "gamma = 0.99\n",
    "episode_training_len = 8\n",
    "\n",
    "\n",
    "env = gym.make(env)\n",
    "set_global_seeds(seed)\n",
    "\n",
    "# Exploration schedule         \n",
    "exploration = LinearSchedule(1.0, final_epsilon, int(num_timesteps * exploration_fraction))\n",
    "\n",
    "# Logging\n",
    "today = datetime.today()\n",
    "date = today.strftime('%d-%m-%Y')\n",
    "time = today.strftime(\"%H:%M:%S\")\n",
    "logger.configure(\"~/logs/\" + date + \"/\" + time + \"/\")\n",
    "\n",
    "\n",
    "# Training\n",
    "train_dqn(\n",
    "    env,\n",
    "    num_timesteps,\n",
    "    replay_size=replay_size,\n",
    "    batch_size=batch_size,\n",
    "    exploration=exploration,\n",
    "    gamma=gamma,\n",
    "    train_freq=train_freq,\n",
    "    print_freq=print_freq,\n",
    "    model_save_freq=model_save_freq,\n",
    "    target_network_update_freq=target_network_update_freq,\n",
    "    num_prepopulate_episode=num_prepopulate_episode, \n",
    "    episode_training_len=episode_training_len\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of DRQN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss plotting\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "with open('loss.pkl', 'rb') as fp:\n",
    "    # read the data as binary data stream\n",
    "    losses_list = pickle.load(fp)\n",
    "    raw = np.array(losses_list)\n",
    "    smooth = rolling_average(raw, window_size=100)\n",
    "\n",
    "plt.plot(smooth, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03395bb83ded4fe4a8a7e32a4d025fac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "03c6167509ea4711b4413186e194f1b7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0719c9d0229d42fcba58072b418da101": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0d8ea23196c84f0da7823de1fd644548": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "acrobot",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_d979c87c55fe464185f3dae6f320cd1c",
       "style": "IPY_MODEL_0fcbe963bf5b456ca3d46a37c184aa92",
       "tooltip": ""
      }
     },
     "0fcbe963bf5b456ca3d46a37c184aa92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "108f2a4bbfce4e698decd627e22be82b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "00.0%",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_c4efca2baa3b46e882e0d77fc9c590cc",
       "style": "IPY_MODEL_430af5381b6842048ae1cfd366c04450",
       "tooltip": ""
      }
     },
     "1093e05d11f2419d98658e46814ee7c5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "10c27de22f3049b093b017e7e053543f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2dd76e0903814266b7271e0a07d0036a",
        "IPY_MODEL_dd74806209c84abeb4cabad05fc9ac7d"
       ],
       "layout": "IPY_MODEL_eabfb1a659d84a2f84a88ead7d4de805"
      }
     },
     "11953ae381ab43cbb2a63c624397a5b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "14645daaf250413c875b77766683593c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "14da2f0e02844c8b9101f1f2b3ec6b7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "100.0%",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_d7795268bee448098d98a15407017057",
       "style": "IPY_MODEL_aea7f58f513b4604b90af5377819ad9c",
       "tooltip": ""
      }
     },
     "14ebdb0dcf824679842134ecf1f5411c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "172dc13ded6742ddb4e34cfdfc0ce1be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f6ab563953894ea99c96769e0d9b8da8",
       "placeholder": "​",
       "style": "IPY_MODEL_3d5cb166f73e4c60ad43dfa132a19ba1",
       "value": " 1500000/1500000 [41:08&lt;00:00, 607.61it/s]"
      }
     },
     "18142ddf08fe400f98d5db0d72aacb30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "50.0%",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_68d20cd15e4e41d1b77168807e3efda7",
       "style": "IPY_MODEL_6fdc39f84da54a17b0d09fcd69f9ef4f",
       "tooltip": ""
      }
     },
     "1a133c2dcecd415199320620653cd731": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1bc404ec873e4c9c833a621b13534041": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "1e1ab65f81e546a6bcec2d9ad14dc981": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6e428b8a731f4634a8b0ff5686609c26",
        "IPY_MODEL_1fa0adaa48ee41869aac33581ca7c8f3"
       ],
       "layout": "IPY_MODEL_1093e05d11f2419d98658e46814ee7c5"
      }
     },
     "1fa0adaa48ee41869aac33581ca7c8f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fa0f91f254cb4e9ab548d1972bf8140c",
       "placeholder": "​",
       "style": "IPY_MODEL_8434e3aa420947548487873b56ac4308",
       "value": " 1500000/1500000 [44:50&lt;00:00, 557.55it/s]"
      }
     },
     "1fb11726ea6f4e49bf4b935cd32b65b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "20f15f9db6204786bf12da1c02b8818c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "00.0%",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_af90bf837dca4751a3ffd777ff142b79",
       "style": "IPY_MODEL_bf88c8d1f7f94cf491ab243012da0e20",
       "tooltip": ""
      }
     },
     "25e2cecd2ac24386ba16b36030a52314": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "27a5daaaa01743ed9fb5ec7575fe23c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "00.0%",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_0719c9d0229d42fcba58072b418da101",
       "style": "IPY_MODEL_64c8c27c8df24648a363acf384379085",
       "tooltip": ""
      }
     },
     "2bf8499868e34f6db8f68f4ef969b86e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "00.0%",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_4fe667fd60a54f659279567c1dbc6bf3",
       "style": "IPY_MODEL_d7c0edddb1e54345970d8666680694fb",
       "tooltip": ""
      }
     },
     "2dd76e0903814266b7271e0a07d0036a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "Episode: 2719 | Steps: 386 | Return: 257.65 | Epsilon: 0.05:  87%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a295e0377b7e408084af75f0e9ffe78f",
       "max": 1500000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6883ee1729e9491283936b734b54df33",
       "value": 1312336
      }
     },
     "2eddf868db06498a9ad173eeff46bc33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "2f685de22c22454d8ac359967460c8a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "35b94dc92db640069b5182e1e12b2d6b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "Episode: 8158 | Steps: 500 | Return: 500.00 | Epsilon: 0.05:  98%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1fb11726ea6f4e49bf4b935cd32b65b1",
       "max": 1500000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5e8fe451ea114cea958151ef57a238fd",
       "value": 1463025
      }
     },
     "37184f69a537453687a529a02f127fcc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "378f41cd11a64d978ce7c59ac01e6816": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "3b4687c409c94199b19535c09d9c788c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3c7d8987f4784e1887c422fd8f4f2caa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "3cf762cac464440fbe0a6f7e8987f53e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3d5cb166f73e4c60ad43dfa132a19ba1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4080a76905d2474e92318126c367ac33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "lunarlander",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_41ccbd193125419eb12315d38b82c5ef",
       "style": "IPY_MODEL_d62bc173a31b48b5968b6b5bc655e1ab",
       "tooltip": ""
      }
     },
     "41225be4361a4933b7ab31b0fa1d66b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "41ccbd193125419eb12315d38b82c5ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "430af5381b6842048ae1cfd366c04450": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "443a7099c02743c9b549f91d58a598df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_27a5daaaa01743ed9fb5ec7575fe23c2",
        "IPY_MODEL_b8c3347aa1a2406f8fdfcd23a8fd056c",
        "IPY_MODEL_18142ddf08fe400f98d5db0d72aacb30",
        "IPY_MODEL_964c1fd12c9b40fa907695c502f4682f",
        "IPY_MODEL_64afbeffcdbb49bf9b7e78b2c684106c"
       ],
       "layout": "IPY_MODEL_5580fcbe05e74e378ff6a8332ca0d8d1"
      }
     },
     "47ae032e0cd046f9af2876318a3d3d16": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_35b94dc92db640069b5182e1e12b2d6b",
        "IPY_MODEL_f0405f22aee4490c828cf20d465d5805"
       ],
       "layout": "IPY_MODEL_25e2cecd2ac24386ba16b36030a52314"
      }
     },
     "488af0ba7ad2454f991055f5046ea08b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "4b405606fcc5474ab22cecfb7ee38889": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "100.0%",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_dcc72758ee124a88844993dfd2a5cc88",
       "style": "IPY_MODEL_d0e8a40ea4e7412aa310416965883c13",
       "tooltip": ""
      }
     },
     "4fe667fd60a54f659279567c1dbc6bf3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "557d0c4420f9424aa49bb55e1d3688e5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5580fcbe05e74e378ff6a8332ca0d8d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5811a9700bbb4f3aa08d110527923b83": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2bf8499868e34f6db8f68f4ef969b86e",
        "IPY_MODEL_6132949b90db46298fec772e2aa48587",
        "IPY_MODEL_b5ac0abe0f2b4b129a1d9be83441552d",
        "IPY_MODEL_8ed603d1ddfd431095ffd89900db1714",
        "IPY_MODEL_4b405606fcc5474ab22cecfb7ee38889"
       ],
       "layout": "IPY_MODEL_920116df058f4d9f958e62ec5622ae4f"
      }
     },
     "5e8fe451ea114cea958151ef57a238fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "6132949b90db46298fec772e2aa48587": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "25.0%",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_63fb9bad79dd44e5ae577156ee029df5",
       "style": "IPY_MODEL_f2e3fc3956b84ba3a5e32565bf1b7131",
       "tooltip": ""
      }
     },
     "61904b27b4fb41c080cc21838f649957": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "25.0%",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_afdbd60d068942918dfa1ca61d5d69f7",
       "style": "IPY_MODEL_3c7d8987f4784e1887c422fd8f4f2caa",
       "tooltip": ""
      }
     },
     "6387a3efbbae41d49e475af0f2b20c3b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "mountaincar",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_7276c7552d07412fb8d660fbe0b7cebe",
       "style": "IPY_MODEL_7f480dcd40d641bdacb47d94f6d9c7f7",
       "tooltip": ""
      }
     },
     "63f83b039f1641eb95ebae8ca471cd30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "63fb9bad79dd44e5ae577156ee029df5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "64afbeffcdbb49bf9b7e78b2c684106c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "100.0%",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_d1b4ce169da543bf9af10ba28a4ec5d0",
       "style": "IPY_MODEL_378f41cd11a64d978ce7c59ac01e6816",
       "tooltip": ""
      }
     },
     "64c8c27c8df24648a363acf384379085": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "682152f5c7374042881e562cf99d43e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "6883ee1729e9491283936b734b54df33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "68d20cd15e4e41d1b77168807e3efda7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6b6b92bc8ce24c1fb330d1f4ac292a5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "6dabafab9edb4dc59a66a11661bed7a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "6e428b8a731f4634a8b0ff5686609c26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "Episode: 9733 | Steps: 102 | Return: -101.00 | Epsilon: 0.05:  94%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_14645daaf250413c875b77766683593c",
       "max": 1500000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fbc5f200d0b34a88bfb12ca4ad37dee4",
       "value": 1413881
      }
     },
     "6fdc39f84da54a17b0d09fcd69f9ef4f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "7276c7552d07412fb8d660fbe0b7cebe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7325c2a283274b15926b3d1c4f9ec9a1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "75f57fee0df54696a62b993b89ad76b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "100.0%",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_f46ee6d99efa49c38be7cf818453d0b5",
       "style": "IPY_MODEL_488af0ba7ad2454f991055f5046ea08b",
       "tooltip": ""
      }
     },
     "78b52f068d5641f48f678edab8dd187d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "75.0%",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_03c6167509ea4711b4413186e194f1b7",
       "style": "IPY_MODEL_2eddf868db06498a9ad173eeff46bc33",
       "tooltip": ""
      }
     },
     "7acc5a9430834923bb413600a1ff4a3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "7cc1e9d61a7842b7b30943c67cb0a35a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7f480dcd40d641bdacb47d94f6d9c7f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "8434e3aa420947548487873b56ac4308": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "85c9d8a1cc9c47e1b3f241dc6e8bb0da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "Episode: 8440 | Steps: 103 | Return: -103.00 | Epsilon: 0.05:  84%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_37184f69a537453687a529a02f127fcc",
       "max": 1500000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_aae6bd2503b54b56a725a6acc403e5fa",
       "value": 1255009
      }
     },
     "876c5a024d5f49b18848e83c503ad2a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "75.0%",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_b8865b0735474ddd8c5b487add496ceb",
       "style": "IPY_MODEL_d7cdd3b5f5d1424b94ca33ad1fd0b800",
       "tooltip": ""
      }
     },
     "8a8c75d7ef7e4d5bb1c271c3fe52858a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "25.0%",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_3cf762cac464440fbe0a6f7e8987f53e",
       "style": "IPY_MODEL_682152f5c7374042881e562cf99d43e4",
       "tooltip": ""
      }
     },
     "8a93061838014b9cad7d811ea8674595": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8b0c91e16966482d8a6227ee7f9f102a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_20f15f9db6204786bf12da1c02b8818c",
        "IPY_MODEL_8a8c75d7ef7e4d5bb1c271c3fe52858a",
        "IPY_MODEL_e0e8344720544fed9d0e851fea96f5a8",
        "IPY_MODEL_78b52f068d5641f48f678edab8dd187d",
        "IPY_MODEL_14da2f0e02844c8b9101f1f2b3ec6b7a"
       ],
       "layout": "IPY_MODEL_7cc1e9d61a7842b7b30943c67cb0a35a"
      }
     },
     "8d7ae72ff1454bc88cfea563a5e02276": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_abb7f594cf3c4ff890e50f5b7213b813",
        "IPY_MODEL_6387a3efbbae41d49e475af0f2b20c3b",
        "IPY_MODEL_0d8ea23196c84f0da7823de1fd644548",
        "IPY_MODEL_4080a76905d2474e92318126c367ac33"
       ],
       "layout": "IPY_MODEL_8a93061838014b9cad7d811ea8674595"
      }
     },
     "8ed603d1ddfd431095ffd89900db1714": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "75.0%",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_dab27813b5f54b829172f03dd4dfc722",
       "style": "IPY_MODEL_6b6b92bc8ce24c1fb330d1f4ac292a5d",
       "tooltip": ""
      }
     },
     "920116df058f4d9f958e62ec5622ae4f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "93fc0fba49d34d47aa0e743002b956fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "956dbe20644a4d519999873dca5ac2fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "964c1fd12c9b40fa907695c502f4682f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "75.0%",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_b624c5db468344b58bc6aa776c6f346c",
       "style": "IPY_MODEL_2f685de22c22454d8ac359967460c8a2",
       "tooltip": ""
      }
     },
     "a1dec277c5d142c0a719a91f73f53dcf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a295e0377b7e408084af75f0e9ffe78f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aae6bd2503b54b56a725a6acc403e5fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "abb7e8dac69341168bb376950940411c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "50.0%",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_557d0c4420f9424aa49bb55e1d3688e5",
       "style": "IPY_MODEL_6dabafab9edb4dc59a66a11661bed7a6",
       "tooltip": ""
      }
     },
     "abb7f594cf3c4ff890e50f5b7213b813": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "cartpole",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_1a133c2dcecd415199320620653cd731",
       "style": "IPY_MODEL_7acc5a9430834923bb413600a1ff4a3f",
       "tooltip": ""
      }
     },
     "aea7f58f513b4604b90af5377819ad9c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "af90bf837dca4751a3ffd777ff142b79": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "afdbd60d068942918dfa1ca61d5d69f7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b5ac0abe0f2b4b129a1d9be83441552d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "50.0%",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_956dbe20644a4d519999873dca5ac2fd",
       "style": "IPY_MODEL_03395bb83ded4fe4a8a7e32a4d025fac",
       "tooltip": ""
      }
     },
     "b624c5db468344b58bc6aa776c6f346c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b8865b0735474ddd8c5b487add496ceb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b8c3347aa1a2406f8fdfcd23a8fd056c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "25.0%",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_7325c2a283274b15926b3d1c4f9ec9a1",
       "style": "IPY_MODEL_11953ae381ab43cbb2a63c624397a5b2",
       "tooltip": ""
      }
     },
     "bf88c8d1f7f94cf491ab243012da0e20": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "c4efca2baa3b46e882e0d77fc9c590cc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d0e8a40ea4e7412aa310416965883c13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "d1b4ce169da543bf9af10ba28a4ec5d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d59c4af19d9d40ba90ef59c0343c9d43": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d62bc173a31b48b5968b6b5bc655e1ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "d7795268bee448098d98a15407017057": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d7c0edddb1e54345970d8666680694fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "d7cdd3b5f5d1424b94ca33ad1fd0b800": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "d979c87c55fe464185f3dae6f320cd1c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dab27813b5f54b829172f03dd4dfc722": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dcc72758ee124a88844993dfd2a5cc88": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dd74806209c84abeb4cabad05fc9ac7d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3b4687c409c94199b19535c09d9c788c",
       "placeholder": "​",
       "style": "IPY_MODEL_41225be4361a4933b7ab31b0fa1d66b8",
       "value": " 1500000/1500000 [56:28&lt;00:00, 442.71it/s]"
      }
     },
     "ddc7e6d2ad7f46afa34a256c321163e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_85c9d8a1cc9c47e1b3f241dc6e8bb0da",
        "IPY_MODEL_172dc13ded6742ddb4e34cfdfc0ce1be"
       ],
       "layout": "IPY_MODEL_1bc404ec873e4c9c833a621b13534041"
      }
     },
     "e0e8344720544fed9d0e851fea96f5a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "50.0%",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_14ebdb0dcf824679842134ecf1f5411c",
       "style": "IPY_MODEL_63f83b039f1641eb95ebae8ca471cd30",
       "tooltip": ""
      }
     },
     "eabfb1a659d84a2f84a88ead7d4de805": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "f0405f22aee4490c828cf20d465d5805": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d59c4af19d9d40ba90ef59c0343c9d43",
       "placeholder": "​",
       "style": "IPY_MODEL_a1dec277c5d142c0a719a91f73f53dcf",
       "value": " 1500000/1500000 [42:45&lt;00:00, 584.77it/s]"
      }
     },
     "f2e3fc3956b84ba3a5e32565bf1b7131": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "f46ee6d99efa49c38be7cf818453d0b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f5e819b37b364128ae18a69acd92b4a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_108f2a4bbfce4e698decd627e22be82b",
        "IPY_MODEL_61904b27b4fb41c080cc21838f649957",
        "IPY_MODEL_abb7e8dac69341168bb376950940411c",
        "IPY_MODEL_876c5a024d5f49b18848e83c503ad2a0",
        "IPY_MODEL_75f57fee0df54696a62b993b89ad76b2"
       ],
       "layout": "IPY_MODEL_93fc0fba49d34d47aa0e743002b956fb"
      }
     },
     "f6ab563953894ea99c96769e0d9b8da8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fa0f91f254cb4e9ab548d1972bf8140c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fbc5f200d0b34a88bfb12ca4ad37dee4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
